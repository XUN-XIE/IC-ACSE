{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "colab_type": "code",
    "id": "LL3vQPYkhzOy",
    "outputId": "259c4a82-dee1-48c3-e0a0-ba3a7b940e77"
   },
   "outputs": [],
   "source": [
    "!pip install pycm livelossplot\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "En9dBOn0hzPL"
   },
   "source": [
    "# ACSE Module 8 - Practical - Morning Session 3:\n",
    "----\n",
    "# Training Deep Neural Networks - Crossvalidation\n",
    "\n",
    "## Task 1: Training a deep neural network on MNIST using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rGURJ5EBhzPO"
   },
   "source": [
    "In this exercise you will use cross-validation to estimate the hyperparameters of a deep-neural network trained on the MNIST dataset and create predictions on the MNIST datasets public test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXJ6R5CBhzPQ"
   },
   "source": [
    "#### A few imports before we get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5-tUzUV2hzPU",
    "outputId": "2645c5e5-8149-4585-93b0-9ea2e2b50045"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "from pycm import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
    "    torch.backends.cudnn.enabled   = False\n",
    "\n",
    "    return True\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
    "    print(\"Cuda installed! Running on GPU!\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"No GPU available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tLRNHc8GOfR"
   },
   "source": [
    "## 1.1: Mounting the google drive for later storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Dg3oP6GHGOsX",
    "outputId": "6a41c0a3-585b-4278-ae68-f933ab5850dd"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_UioFmvFIDw"
   },
   "source": [
    "## 1.2: The MNIST Dataset - Hello World of Deep-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3K-yVuQvhzPs"
   },
   "outputs": [],
   "source": [
    "mnist_train = MNIST(\"./\", download=True, train=True)\n",
    "mnist_test = MNIST(\"./\", download=True, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZIKWFh11AK_Y"
   },
   "source": [
    "## 1.3: Instantiate and create a ```StratifiedShuffleSplit``` using sklearn.\n",
    "1. Create a ```sklearn.model_selection.StratifiedShuffleSplit``` object with 1-split and a test-size of 10%.\n",
    "2. Get the training and validation indices from the shuffel-split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "euZacTUtALq7"
   },
   "source": [
    "## 1.4: Splitting and normalize the data\n",
    "The original mnist data is given in gray-scale values between 0 and 255.\n",
    "You will need to write a normalisation method that takes in a ```torch.Tensor``` and performs normalisation.\n",
    "The mean of MNIST is 0.1307 and it's standard deviation is 0.3081 (after division by 255).\n",
    "\n",
    "Finally, torch likes all categorical data to be in a ```.long()``` format.\n",
    "Therefore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RM9owG-yAMLv"
   },
   "source": [
    "## 1.5: Instantiate a ```torch.utils.data.TensorDataset``` for training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZ2qMRUGAEUA"
   },
   "source": [
    "Let's visualise an example of the images and check whether the data is normalised properly (compute .mean() and .std() on the training set.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pQScGYoWSZtj"
   },
   "source": [
    "## 1.6: Create a SimpleNet as a ```nn.Module```\n",
    "Create a simple feed-forward neural network with the following architecture:\n",
    "- Input Layer: 28*28 neurons\n",
    "- Hidden Layer: 25 neurons\n",
    "- Output Layer: 10 neurons\n",
    "- Hidden Layer Activation: ReLU\n",
    "- Output Layer Activation: None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3TYLEVrsANtX"
   },
   "source": [
    "## 1.7: Sanity checks on our SimpleNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "cPxBHE2MhzQA",
    "outputId": "1cec26a8-c336-4405-c5dd-be79c6a574e4"
   },
   "outputs": [],
   "source": [
    "model = SimpleNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "X_ = X_train[0].view(-1, 28*28).to(device)\n",
    "y_ = torch.zeros((1)).to(device).long()\n",
    "\n",
    "a2 = model(X_)\n",
    "loss = criterion(a2, y_)\n",
    "\n",
    "y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
    "\n",
    "print(F.log_softmax(a2, dim=1))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bcFPI8XKAOtl"
   },
   "source": [
    "## 1.8: Create simple train function\n",
    "\n",
    "The function should perform the following tasks:\n",
    "1. Set the model into training mode\n",
    "2. Iterate over all the mini-batches\n",
    "3. Send the batches to the GPU / CPU\n",
    "4. Zero all the gradients\n",
    "5. Perform the forward-pass\n",
    "6. Compute the loss\n",
    "7. Perform the backward-pass\n",
    "8. Keep a running measure of training loss and accuracy\n",
    "9. Perform a step of gradient-descent\n",
    "10. Once done with all batches, return average training loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FRrehKxjhzQQ"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, data_loader):\n",
    "    model.train()\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "    for X, y in data_loader:\n",
    "        X, y = X.to(device), y.to(device)  \n",
    "        \n",
    "    return train_loss/len(data_loader.dataset), train_accuracy/len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ZyumfW0AQDE"
   },
   "source": [
    "## 1.9 Create simple validate function\n",
    "\n",
    "The function should perform the following tasks:\n",
    "1. Set the model into evaluation mode\n",
    "2. Iterate over all the mini-batches\n",
    "3. Send the batches to the GPU / CPU\n",
    "5. Perform the forward-pass\n",
    "6. Compute the loss\n",
    "8. Keep a running measure of validation loss and accuracy\n",
    "10. Once done with all batches, return average validation loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Br0jvB7-hzQZ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def validate(model, criterion, data_loader):\n",
    "    model.eval()\n",
    "    validation_loss, validation_accuracy = 0., 0.\n",
    "    for X, y in data_loader:\n",
    "        with torch.no_grad():\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "    return validation_loss/len(data_loader.dataset), validation_accuracy/len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_pehihNAQ9E"
   },
   "source": [
    " ## 1.10: Set the hyperparameters of your model\n",
    "- Seed: 42\n",
    "- learning rate: 1e-2\n",
    "- Optimizer: SGD\n",
    "- momentum: 0.9\n",
    "- Number of Epochs: 30\n",
    "- Batchsize: 64\n",
    "- Test Batch Size (no effect on training apart from time): 1000\n",
    "- Shuffle the training set every epoch: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zvp3L6IGhzQj"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "lr = 1e-2\n",
    "momentum = 0.9\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "n_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-QgnLf8fJ8nG"
   },
   "source": [
    "## 1.11: Instantiate our model, optimizer and loss function\n",
    "Set the random number generator seed using ```set_seed``` to make everything reproducible.\n",
    "As a criterion use a sensible loss for the multi-class classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZfBaeCSiASt7"
   },
   "source": [
    "## 1.12: Create dataloaders for the training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NMEpCuC1EEFw"
   },
   "source": [
    "## 1.13: Perform the training of the network and validation\n",
    "Here we provide you with a method to visualize both training and validation loss while training your networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "colab_type": "code",
    "id": "w9txG8N2hzQt",
    "outputId": "cfe6c275-dcdf-4b26-8424-b044ca0b8d6d"
   },
   "outputs": [],
   "source": [
    "liveloss = PlotLosses()\n",
    "for epoch in range(30):\n",
    "    logs = {}\n",
    "    train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
    "\n",
    "    logs['' + 'log loss'] = train_loss.item()\n",
    "    logs['' + 'accuracy'] = train_accuracy.item()\n",
    "    \n",
    "    validation_loss, validation_accuracy = validate(model, criterion, validation_loader)\n",
    "    logs['val_' + 'log loss'] = validation_loss.item()\n",
    "    logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
    "    \n",
    "    liveloss.update(logs)\n",
    "    liveloss.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5kPt1sm8Mm_q"
   },
   "source": [
    "It seems the model isn't doing very well. Maybe we can do better.\n",
    "\n",
    "## 1.14: Running a grid-search\n",
    "Run a grid search over the momentum value, use the following: momentum = [0.1, 0.5, 0.9]\n",
    "and run the model on the full training set with the best value for the momentum parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVIuIJuTM2Ro"
   },
   "outputs": [],
   "source": [
    "def train_model(momentum):\n",
    "  set_seed(seed)\n",
    "  model = SimpleNet().to(device)\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  \n",
    "  train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "  validation_loader = DataLoader(mnist_validate, batch_size=test_batch_size, shuffle=False, num_workers=0)\n",
    "  test_loader = DataLoader(mnist_test, batch_size=test_batch_size, shuffle=False, num_workers=0)\n",
    "  \n",
    "  liveloss = PlotLosses()\n",
    "  for epoch in range(30):\n",
    "      logs = {}\n",
    "      train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
    "\n",
    "      logs['' + 'log loss'] = train_loss.item()\n",
    "      logs['' + 'accuracy'] = train_accuracy.item()\n",
    "\n",
    "      validation_loss, validation_accuracy = validate(model, criterion, validation_loader)\n",
    "      logs['val_' + 'log loss'] = validation_loss.item()\n",
    "      logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
    "\n",
    "      liveloss.update(logs)\n",
    "      liveloss.draw()\n",
    "      \n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "0G3oP1vPNE2O",
    "outputId": "51d041b1-e416-4d63-ac26-5e7c8051415d"
   },
   "outputs": [],
   "source": [
    "train_model(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "EA9rn-x3NFEP",
    "outputId": "07834c00-7057-41de-ac02-155cdabcf362"
   },
   "outputs": [],
   "source": [
    "train_model(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "82leJRKPNFOk",
    "outputId": "47733524-9380-4df6-d09e-4e0c3a6e1307"
   },
   "outputs": [],
   "source": [
    "train_model(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "biyWFx8tAW9G"
   },
   "source": [
    "## 1.15: Implement an evaluate method\n",
    "This method performs the same as validate but doesn't report losses, but simply returns all predictions on a given dataset (training, validation, test-set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1-MaI8F1hzQ7"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    ys, y_preds = [], []\n",
    "    for X, y in data_loader:\n",
    "        with torch.no_grad():\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "    return np.concatenate(y_preds, 0),  np.concatenate(ys, 0)\n",
    "\n",
    "y_pred, y_gt = evaluate(model, validation_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "keGazNqkAXw9"
   },
   "source": [
    "## 1.17: Plotting a confusion matrix\n",
    "\n",
    "We can use a confusion matrix to diagnose problems in our models.\n",
    "We may see for example that our model confuses 9's for 4's quite often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2449
    },
    "colab_type": "code",
    "id": "SWtJhZnDhzRE",
    "outputId": "c8424d84-e340-4665-bbc4-748220313301",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(actual_vector=y_gt, predict_vector=y_pred) # Create CM From Data\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-OG3gAcE2mr"
   },
   "source": [
    "## 1.18: Given that you estimated your hyperparameters, train your model on the full dataset and evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QefvYkcIAaWH"
   },
   "source": [
    "## 2.1: Storing and loading models - Pytorch State-Dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6db2OqwdAb7V"
   },
   "source": [
    "Pytorch stores all the parameters of models and optimizers, their weights and biases in an easy to read dictionary called a \"state-dict\".\n",
    "When we store models and optimizers, we store the state-dict.  \n",
    "Together with the model definition we can then restore the model to it's state when we stored it to disk.\n",
    "Let's look at the contents of the state-dict of both our optimizer and our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1259
    },
    "colab_type": "code",
    "id": "YzY_uubq_uqM",
    "outputId": "04d48c9c-2333-4866-b0b3-7689131360bb"
   },
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EjiWkU_TGJgK"
   },
   "source": [
    "## 2.2: Storing models to disk\n",
    "From colab (and locally) we can store models to disk using ```torch.save``` and passing both a models state_dict() and a path where to store it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjOcO8oxGJt0"
   },
   "outputs": [],
   "source": [
    "model_save_name = 'simplenet_mnist_classifier.pt'\n",
    "path = F\"/content/gdrive/My Drive/models/{model_save_name}\" \n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_OiqJ0HOF6hq"
   },
   "source": [
    "## 2.3: Loading models from checkpoints\n",
    "Finally, we can restore models from the saved ```state_dict```'s and do a number of things such as:\n",
    "1. Continue training (given we stored the optimizer as well)\n",
    "2. Make predictions from our model\n",
    "3. Perform inspections of our model\n",
    "4. Use our model in ensembles \n",
    "5. ...\n",
    "\n",
    "By default a loaded model is put into ```.train()``` mode. So be careful when using networks that behave different depending on training and test time e.g. dropout regularized networks or batch-normalized networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "8t4FzhqVF6vh",
    "outputId": "a6db6d8e-0387-4d13-d6d6-6fd25199185b"
   },
   "outputs": [],
   "source": [
    "model = SimpleNet().to(device)\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "\n",
    "test_loss, test_accuracy = validate(model, criterion, test_loader)    \n",
    "print(\"Avg. Test Loss: %1.3f\" % test_loss.item(), \" Avg. Test Accuracy: %1.3f\" % test_accuracy.item())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uhSLXauWHmZ2"
   },
   "source": [
    "Our model performs exactly the same as before storing it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DV5_Nma1HhNj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Morning Session 3 - MNIST-Neural-Networks-Regularization-Cross-Validation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
