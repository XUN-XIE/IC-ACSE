{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "ve6YuUQk_rgb",
    "outputId": "7bbd836b-bbce-42a9-a9b9-4cc5842a8e9a"
   },
   "outputs": [],
   "source": [
    "### Some useful imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomRotation, ToPILImage\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# We tested the difference between accuracy_score and f1_score \n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "!pip install pycm livelossplot\n",
    "%pylab inline\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "from pycm import *\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "FrfkAe0D_rgk",
    "outputId": "24ea2a6d-7daf-4851-cd25-3afcd7f36a46"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Op9QYdji_5kV"
   },
   "outputs": [],
   "source": [
    "# Unzip the data file in the google drive\n",
    "!unzip -q \"/content/gdrive/My Drive/acse-miniproject.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KPTlDhmF_rgq",
    "outputId": "8c97b124-713f-4853-8b26-28b36f366e19"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Use this to set ALL the random seeds to a fixed value \n",
    "    and take out any randomness from cuda kernels.\n",
    "    \n",
    "    seed, the seed number.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
    "    torch.backends.cudnn.enabled   = False\n",
    "\n",
    "    return True\n",
    "\n",
    "# Set the random seed at the begining of code \n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fJolfn2L_rgu",
    "outputId": "71177c27-135f-48a0-e1e4-57c7557bdf87"
   },
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
    "    print(\"Cuda installed! Running on GPU!\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"No GPU available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Msn6oAYL_rgx"
   },
   "source": [
    "# 1. get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LH7iq2H_rgy"
   },
   "source": [
    "### Load classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDg9zmS3_rgz"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from scipy import misc\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjEyB87R_rg1"
   },
   "outputs": [],
   "source": [
    "def load_mapping(fname):\n",
    "    '''\n",
    "    Load the classes from the json file.\n",
    "    \n",
    "    fname, the path of the json file.  \n",
    "    '''\n",
    "    with open(fname, mode=\"r\") as f:\n",
    "        folder_to_class = json.load(f)\n",
    "    \n",
    "    return folder_to_class\n",
    "\n",
    "classes = load_mapping(\"./mapping.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wUSh2Skt_rg8"
   },
   "outputs": [],
   "source": [
    "def load_train_data(data_dir):\n",
    "    '''\n",
    "    Load the training data and its lables from the file directory.\n",
    "    Count the number of gray images to see their proportion and \n",
    "    change them to 3-channel images.\n",
    "    \n",
    "    data_dir, the directory of training data.  \n",
    "    '''\n",
    "    count = 0\n",
    "    gray_count = 0\n",
    "    all_images = []\n",
    "    labels = []\n",
    "    tmp_label = 0\n",
    "    \n",
    "    for guy in os.listdir(data_dir):\n",
    "        # Something in files but shouldn't be included\n",
    "        if guy == '.DS_Store':\n",
    "            continue\n",
    "        \n",
    "        # Set the corresponding labels for different images\n",
    "        tmp_label = classes[guy]\n",
    "        \n",
    "        # Path of folder of each class\n",
    "        person_dir_1 = pjoin(data_dir, guy)\n",
    "        # Path of \"images\" folder of each class\n",
    "        person_dir = pjoin(person_dir_1, \"images\")\n",
    "        for i in os.listdir(person_dir):\n",
    "            # Path of each image\n",
    "            image_dir = pjoin(person_dir, i)\n",
    "            img2 = Image.open(image_dir)\n",
    "            img2=np.array(img2)\n",
    "            \n",
    "            # Process the gray-image\n",
    "            if len(img2.shape) == 2:\n",
    "                img2 = np.stack((img2, img2, img2), axis=-1)\n",
    "                gray_count+=1\n",
    "        \n",
    "            all_images.append(img2)\n",
    "            labels.append(tmp_label)\n",
    "            count = count+1\n",
    "    print(count)\n",
    "    \n",
    "    return count, all_images, gray_count, labels\n",
    "\n",
    "class MiniDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the arguments of a dataset.\n",
    "        \n",
    "        data (Tensor), a tensor containing the data e.g. images\n",
    "        targets (Tensor), a tensor containing all the labels\n",
    "        transform (callable, optional), optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample, label = self.data[idx], self.targets[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample, label\n",
    "\n",
    "# taken from: https://discuss.pytorch.org/t/torch-utils-data-dataset-random-split/32209/4 (Thanks ptrblk!)\n",
    "class Subset2Dataset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the arguments of a sub dataset.\n",
    "        \n",
    "        subset (Tensor), a tensor containing the data \n",
    "        transform (callable, optional), optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bd8axBtV_rg5",
    "outputId": "0210aacb-9a26-49f3-89e9-4f2deeb174a8"
   },
   "outputs": [],
   "source": [
    "# Get the images(np.array) and labels of training data\n",
    "all_count, images, gray_count, labels = load_train_data(\"./train\")\n",
    "\n",
    "# See the proportion of gray images\n",
    "prop = gray_count/all_count \n",
    "\n",
    "print(\"The total number of training data: %d\\nThe proportion of gray images: %.3f\"%(all_count,prop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mj_-K8Z1IGnJ"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Calculate the mean and standard deviation of images\n",
    "means = [(images[:, i, :, :]/255).mean() for i in range(3)]\n",
    "std = [(images[:, i, :, :]/255).std() for i in range(3)]\n",
    "'''\n",
    "\n",
    "# Because above takes a lot of computation so we just save the values to use directly\n",
    "means = [0.48024578664981976, 0.44807218089384243, 0.3975477478649683]\n",
    "stds = [0.27698640690882403, 0.26906448510256065, 0.28208190621058304]\n",
    "\n",
    "augs = [\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        ### Transforms we decide not to use\n",
    "        # transforms.RandomRotation(10),\n",
    "        # transforms.RandomCrop(224, padding=4)\n",
    "]\n",
    "\n",
    "# Transforms used for training set\n",
    "train_transform = Compose([\n",
    "    ToPILImage(), \n",
    "    augs[0],\n",
    "    # transforms.ColorJitter(brightness=0.3),\n",
    "    # augs[1],\n",
    "    # augs[2],\n",
    "    transforms.Resize(224),\n",
    "    ToTensor(),\n",
    "    transforms.Normalize(means, stds)\n",
    "])\n",
    "\n",
    "# Transforms used for validation set and test set\n",
    "val_transform = Compose([\n",
    "    ToPILImage(),\n",
    "    transforms.Resize(224),\n",
    "    ToTensor(),\n",
    "    transforms.Normalize(means, stds),\n",
    "])\n",
    "\n",
    "# The dataset containing all the training data\n",
    "MiniTrain_train = MiniDataset(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uohNgae4RZ5k"
   },
   "source": [
    "## Run the following cell only once for ***EACH RUNTIME***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IgrygBgqFjHy",
    "outputId": "189a0380-a90a-458b-fbc9-dd55ca4ed6a3"
   },
   "outputs": [],
   "source": [
    "# Split the whole training data to training, validation and test sets\n",
    "train_size, val_size, test_size = 80000, 10000, 10000\n",
    "train_subset, val_subset, test_subset = random_split(MiniTrain_train, [train_size, val_size, test_size])\n",
    "\n",
    "# Do the corresponding transforms to the three subsets\n",
    "train_set = Subset2Dataset(train_subset, transform=train_transform)\n",
    "val_set   = Subset2Dataset(val_subset, transform=val_transform)\n",
    "test_set  = Subset2Dataset(test_subset, transform=val_transform)\n",
    "\n",
    "print(\"The length of training set: %d\\n\\\n",
    "The length of validation set: %d\\n\\\n",
    "The length of test set: %d\\n\"%(len(train_set), len(val_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aa36HcTE_rhE"
   },
   "outputs": [],
   "source": [
    "def load_test_data(data_dir):\n",
    "    '''\n",
    "    Load the test data from the file directory.\n",
    "    Count the number of gray images to see their proportion and \n",
    "    change them to 3-channel images.\n",
    "    \n",
    "    data_dir, the directory of test data.  \n",
    "    '''\n",
    "    count = 0\n",
    "    gray_count = 0\n",
    "    all_images = []\n",
    "    file_name = []\n",
    "\n",
    "    # Path of \"images\" folder \n",
    "    person_dir = pjoin(data_dir, \"images\")\n",
    "    for i in os.listdir(person_dir):\n",
    "        # Path of each image\n",
    "        image_dir = pjoin(person_dir, i)  \n",
    "        \n",
    "        # something in files but shouldn't be included\n",
    "        if i == \".ipynb_checkpoints\":\n",
    "            continue\n",
    "        tmp_file = i\n",
    "        # Get the filenames of test images\n",
    "        file_name.append(i.lower())\n",
    "        \n",
    "        img2 = Image.open(image_dir)\n",
    "        img2=np.array(img2)\n",
    "\n",
    "        # Process the gray-image\n",
    "        if len(img2.shape) == 2:\n",
    "            img2 = np.stack((img2, img2, img2), axis=-1)\n",
    "            gray_count+=1\n",
    "\n",
    "        all_images.append(img2)\n",
    "        \n",
    "        count = count+1\n",
    "    print(count)\n",
    "    \n",
    "    return count, all_images, gray_count, file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hAjuWsZj_rhH",
    "outputId": "dd4f03b8-88ee-4cf2-e547-224862c6d201"
   },
   "outputs": [],
   "source": [
    "# Get the images(np.array) and filenames of test data\n",
    "all_count, test_images, gray_count, file_name = load_test_data(\"./test\")\n",
    "test_labels = torch.zeros([10000], dtype=torch.int32)\n",
    "\n",
    "# The dataset containing all the test data\n",
    "MiniTest = MiniDataset(test_images, test_labels, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6TND878NN4C"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, data_loader):\n",
    "    '''\n",
    "    Train the model with provided training data.\n",
    "\n",
    "    model, the neutral network\n",
    "    optimizer, optimizer used to update the weight parameters\n",
    "    criterion, criterion used to calculate the loss\n",
    "    data_loader, the training dataloader\n",
    "    '''\n",
    "    model.train()\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "    for X, y in data_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        a2 = model(X)\n",
    "        loss = criterion(a2, y)\n",
    "        loss.backward()\n",
    "        train_loss += loss*X.size(0)\n",
    "        y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
    "        train_accuracy += f1_score(y.cpu().numpy(), y_pred.detach().cpu().numpy(),average='macro')*X.size(0)\n",
    "        optimizer.step()  \n",
    "        \n",
    "    return train_loss/len(data_loader.dataset), train_accuracy/len(data_loader.dataset)\n",
    "  \n",
    "def validate(model, criterion, data_loader):\n",
    "    '''\n",
    "    Test the model with provided validation data.\n",
    "\n",
    "    model, the neutral network\n",
    "    criterion, criterion used to calculate the loss\n",
    "    data_loader, the validation dataloader\n",
    "    '''\n",
    "    model.eval()\n",
    "    validation_loss, validation_accuracy = 0., 0.\n",
    "    for X, y in data_loader:\n",
    "        with torch.no_grad():\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            a2 = model(X)\n",
    "            loss = criterion(a2, y)\n",
    "            validation_loss += loss*X.size(0)\n",
    "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
    "            validation_accuracy += f1_score(y.cpu().numpy(), y_pred.cpu().numpy(),average='macro')*X.size(0)\n",
    "            \n",
    "    return validation_loss/len(data_loader.dataset), validation_accuracy/len(data_loader.dataset)\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    '''\n",
    "    Evaluate the model with test data(no label) and output a .csv file.\n",
    "\n",
    "    model, the trained model\n",
    "    data_loader, the test dataloader\n",
    "    '''\n",
    "    model.eval()\n",
    "    f = open('test_result.csv', 'w+')\n",
    "    with f:\n",
    "        fnames = ['Filename', 'Label']\n",
    "        writer = csv.DictWriter(f, fieldnames=fnames)    \n",
    "        writer.writeheader()\n",
    "        i=0\n",
    "        for X, y in data_loader:\n",
    "            with torch.no_grad():\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                a2 = model(X)\n",
    "                y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
    "                for x in range(1000):\n",
    "                    writer.writerow({'Filename' : file_name[i], 'Label': y_pred[x].item()}) \n",
    "                    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Snxp54baIXIq"
   },
   "outputs": [],
   "source": [
    "def train_model(model, momentum=0.5, weight_decay=0, lr=0.02, n_epochs=5, batch_size=64, test_batch_size=1000, best_accuracy=0, save_file=False, model_save_name=None):\n",
    "\n",
    "    '''\n",
    "    Train the model with training dataset and validate dataset.\n",
    "\n",
    "    model, the neutral network\n",
    "    momentum, the parameter that helps accelerate optimizer\n",
    "    weight_deacy, the parameter of L2-Regularization\n",
    "    lr, the learning rate of optimizer\n",
    "    n_epochs, the number of epochs\n",
    "    batch_size, the batch size of training set\n",
    "    test_batch_size, the batch size of validation and test sets\n",
    "    save_file, whether to save the model file of this training\n",
    "    model_save_name, the path of file you want to save\n",
    "\n",
    "    '''\n",
    "    if save_file and not model_save_name:\n",
    "        print(\"No file name specified.\")\n",
    "        return\n",
    "        \n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    validation_loader = DataLoader(val_set, batch_size=test_batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    liveloss = PlotLosses()\n",
    "    for epoch in range(n_epochs):\n",
    "        logs = {}\n",
    "        train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
    "\n",
    "        logs['' + 'log loss'] = train_loss.item()\n",
    "        logs['' + 'accuracy'] = train_accuracy.item()\n",
    "\n",
    "        validation_loss, validation_accuracy = validate(model, criterion, validation_loader)\n",
    "        logs['val_' + 'log loss'] = validation_loss.item()\n",
    "        logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
    "\n",
    "        liveloss.update(logs)\n",
    "        liveloss.draw()\n",
    "\n",
    "        if save_file and validation_accuracy.item() > best_accuracy:\n",
    "            best_accuracy = validation_accuracy.item()\n",
    "            path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
    "            torch.save(model.state_dict(), path)\n",
    "            print(\"Model %s saved (epoch: %s)\" % (model_save_name, epoch + 1))\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNvbDhJw39SD"
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_batch_size=1000):\n",
    "    '''\n",
    "    Test the trained model with test dataset.\n",
    "\n",
    "    model, the neutral network\n",
    "    test_batch_size, the batch size of validation and test sets\n",
    "    '''\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    test_loader = DataLoader(test_set, batch_size=test_batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    test_loss, test_accuracy = validate(model, criterion, test_loader)    \n",
    "    print(\"Avg. Test Loss: %1.3f\" % test_loss.item(), \" Avg. Test Accuracy: %1.3f\" % test_accuracy.item())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6LS6by-_8n_h",
    "outputId": "17121edb-2c5f-4761-9de0-cdea6709186b"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Import the model\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "# Change the number of output classes\n",
    "fc_in = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(fc_in, 200)\n",
    "resnet18.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "qdMFEJIF87Mx",
    "outputId": "edaff0e7-b92c-4c70-d7f5-064cf438960a"
   },
   "outputs": [],
   "source": [
    "# First 3 epochs for ResNet18\n",
    "resnet18_try = train_model(resnet18, n_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "outyL7bGQdS8",
    "outputId": "b8844cf8-0567-48ab-a201-9f8f82fa6eac"
   },
   "outputs": [],
   "source": [
    "test_model(resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-4mFpB9aEll"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "eval_loader = DataLoader(MiniTest, batch_size=1000, shuffle=False, num_workers=4)\n",
    "evaluate(resnet50, eval_loader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "likelihood_imp_ver.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
