{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Floating point numbers\n",
    "## Or why `x == y` is bad...\n",
    "\n",
    "### Recommend reading:\n",
    "#### What Every Computer Scientist Should Know About Floating-Point Arithmetic\n",
    "https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1\n",
    "y = 1/3\n",
    "\n",
    "assert x == 3*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.float_info(max=1.7976931348623157e+308, max_exp=1024, max_10_exp=308, min=2.2250738585072014e-308, min_exp=-1021, min_10_exp=-307, dig=15, mant_dig=53, epsilon=2.220446049250313e-16, radix=2, rounds=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.float_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.float64(1)\n",
    "y = np.float64(1/3)\n",
    "\n",
    "assert x == 3*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cc0fd1eb293b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = np.float32(1)\n",
    "y = np.float32(1/3)\n",
    "\n",
    "assert x == 3*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2ff1b7ec6464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m0.3\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 0.3 == 0.1 + 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: Adding from large to small\n",
      "1 5.000000e+00 + 5.000000e-01 = 5.500000e+00\n",
      "2 5.500000e+00 + 5.000000e-02 = 5.550000e+00\n",
      "3 5.550000e+00 + 5.000000e-03 = 5.555000e+00\n",
      "4 5.555000e+00 + 5.000000e-04 = 5.555501e+00\n",
      "5 5.555501e+00 + 5.000000e-05 = 5.555551e+00\n",
      "6 5.555551e+00 + 5.000000e-06 = 5.555555e+00\n",
      "7 5.555555e+00 + 5.000000e-07 = 5.555556e+00\n",
      "sum = 5.555556e+00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L = 8\n",
    "\n",
    "vals = np.array([5*10**-i for i in range (L)], dtype=np.float32)\n",
    "\n",
    "print(\"Trial 1: Adding from large to small\")\n",
    "sum1 = vals[0]\n",
    "for i in range(1, L):\n",
    "    print(i, \"%e + %e = %e\"%(sum1, vals[i], sum1+vals[i]))\n",
    "    sum1 += vals[i]\n",
    "print (\"sum = %e\\n\"%sum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2: Adding from small to large\n",
      "6 5.000000e-07+5.000000e-06 = 5.500000e-06\n",
      "5 5.500000e-06+5.000000e-05 = 5.550000e-05\n",
      "4 5.550000e-05+5.000000e-04 = 5.555000e-04\n",
      "3 5.555000e-04+5.000000e-03 = 5.555500e-03\n",
      "2 5.555500e-03+5.000000e-02 = 5.555550e-02\n",
      "1 5.555550e-02+5.000000e-01 = 5.555555e-01\n",
      "0 5.555555e-01+5.000000e+00 = 5.555555e+00\n",
      "sum = 5.555555e+00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Trial 2: Adding from small to large\")\n",
    "sum2 = vals[L-1]\n",
    "for i in range(L-2, -1, -1):\n",
    "    print(i, \"%e+%e = %e\"%(sum2, vals[i], sum2+vals[i]))\n",
    "    sum2 += vals[i]\n",
    "print (\"sum = %e\\n\"%sum2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle trial  0: sum = 5.555555e+00 \n",
      "Shuffle trial  1: sum = 5.555555e+00 \n",
      "Shuffle trial  2: sum = 5.555556e+00 \n",
      "Shuffle trial  3: sum = 5.555556e+00 \n",
      "Shuffle trial  4: sum = 5.555555e+00 \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for trial in range(5):\n",
    "    random.shuffle(vals)\n",
    "    print(\"Shuffle trial %2d: sum = %e \"%(trial, vals.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical considerations using floating-point arithmetic\n",
    "### Adapted from https://en.wikipedia.org/wiki/Numerical_differentiation\n",
    "\n",
    "Example below showing the difficulty of choosing $h$ due to both rounding error and formula error.\n",
    "\n",
    "An important consideration in practice when the function is calculated using floating-point arithmetic is how small a value of $h$ to choose. If chosen too small, the subtraction will yield a large rounding error. In fact, all the finite-difference formulae are ill-conditioned and due to cancellation will produce a value of zero if $h$ is small enough. If too large, the calculation of the slope of the secant line will be more accurately calculated, but the estimate of the slope of the tangent by using the secant could be worse.\n",
    "\n",
    "![alt text](./AbsoluteErrorNumericalDifferentiationExample.png)\n",
    "\n",
    "For the numerical derivative formula evaluated at $x$ and $x + h$, a choice for $h$ that is small without producing a large rounding error is $x\\sqrt{\\varepsilon}$ (though not when $x = 0$), where the machine epsilon $\\varepsilon$ is typically of the order of $2.2 \\times 10^{−16}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So... what gives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floating Point Numbers\n",
    "### Taken from http://www.doc.ic.ac.uk/~eedwards/compsys/float/\n",
    "\n",
    "**Real Numbers**: `pi=3.14159265`... `e = 2.71828`...\n",
    "\n",
    "**Scientific Notation**: has a single digit to the left of the decimal point.\n",
    "\n",
    "**A number in Scientific Notation with no leading 0's is called a Normalized Number**: $1.0 \\times 10^{-8}$\n",
    "\n",
    "**Not in normalized form**: $0.1 \\times 10^{-7}$ or $10.0 \\times 10^{-9}$\n",
    "\n",
    "**Can also represent binary numbers in scientific notation**: $1.0 \\times 2^{-3}$\n",
    "\n",
    "Computer arithmetic that supports such numbers is called Floating Point.\n",
    "\n",
    "The form is $s \\times 1.xxxx… \\times 2yy…$.\n",
    "\n",
    "Using normalized scientific notation:\n",
    "- Simplifies the exchange of data that includes floating-point numbers\n",
    "- Simplifies the arithmetic algorithms to know that the numbers will always be in this form\n",
    "- Increases the accuracy of the numbers that can be stored in a word, since each unnecessary leading 0 is replaced by another significant digit to the right of the decimal point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation of Floating-Point numbers\n",
    "\n",
    "$$-1^S \\times M \\times 2^E$$\n",
    "\n",
    "|Bit No|Size    |Field Name  |\n",
    "|------|--------|------------|\n",
    "|31\t   |1 bit \t|Sign (S)    |\n",
    "|23-30 |8 bits\t|Exponent (E)|\n",
    "|0-22  |23 bits\t|Mantissa (M)|\n",
    "\n",
    "A Single-Precision floating-point number occupies 32-bits, so there is a compromise between the size of the mantissa and the size of the exponent.\n",
    "\n",
    "These chosen sizes provide a range of approx:\n",
    "\n",
    "$$\\pm 10^{-38} ... 10^{38}$$\n",
    "\n",
    "To reduce the chances of rounding errors, developers often use 64-bit Double-Precision arithmetic. **However, there is no such thing as a free lunch** as this doubles the memory requirements and increases the cost of the computation (and indeed doesn't always work).\n",
    "\n",
    "|Bit No\t|Size\t |Field Name  |\n",
    "|-------|--------|------------|\n",
    "|63\t    |1 bit \t |Sign (S)    |\n",
    "|52-62\t|11 bits |Exponent (E)|\n",
    "|0-51\t|52 bits |Mantissa (M)|\n",
    "\n",
    "providing a range of\n",
    "\n",
    "$\\pm 10^{-308} ... 10^{308}$\n",
    "\n",
    "These formats are called ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IEEE 754 Floating-Point Standard\n",
    "\n",
    "Since the mantissa is always 1.xxxxxxxxx in the normalised form, no need to represent the leading 1. So, effectively:\n",
    "\n",
    "- Single Precision: mantissa ===> 1 bit + 23 bits\n",
    "- Double Precision: mantissa ===> 1 bit + 52 bits\n",
    "\n",
    "Since zero (0.0) has no leading 1, to distinguish it from others, it is given the reserved bit pattern all 0s for the exponent so that hardware won't attach a leading 1 to it. Thus:\n",
    "\n",
    "- Zero (0.0) = 0000...0000\n",
    "- Other numbers = $-1^S \\times (1 + Mantissa) \\times 2^E$\n",
    "\n",
    "If we number the mantissa bits from left to right m1, m2, m3, ...\n",
    "\n",
    "$mantissa = m1 \\times 2^{-1} + m2 \\times 2^{-2} + m3 \\times 2^{-3} + ....$\n",
    "\n",
    "Negative exponents could pose a problem in comparisons.\n",
    "\n",
    "For example (with two's complement):\n",
    "\n",
    "|                    |Sign|Exponent|Mantissa                 |\n",
    "|--------------------|----|--------|-------------------------|\n",
    "|$1.0 \\times 2^{-1}$ |0   |11111111|0000000 00000000 00000000|\n",
    "|$1.0 \\times 2^{+1}$ |0   |00000001|0000000 00000000 00000000|\n",
    "\n",
    "With this representation, the first exponent shows a \"larger\" binary number, making direct comparison more difficult.\n",
    "\n",
    "To avoid this, **Biased Notation** is used for exponents.\n",
    "\n",
    "If the real exponent of a number is X then it is represented as (X + bias)\n",
    "\n",
    "IEEE single-precision uses a bias of 127. Therefore, an exponent of\n",
    "\n",
    "|||\n",
    "|---|--------------------------------------------|\n",
    "|-1 |is represented as -1 + 127 = 126 = 011111102|\n",
    "| 0 |is represented as  0 + 127 = 127 = 011111112|\n",
    "|+1 |is represented as +1 + 127 = 128 = 100000002|\n",
    "|+5 |is represented as +5 + 127 = 132 = 100001002|\n",
    "\n",
    "So the actual exponent is found by subtracting the bias from the stored exponent. Therefore, given S, E, and M fields, an IEEE floating-point number has the value:\n",
    "\n",
    "$-1^S \\times (1.0 + 0.M) \\times 2^{E-bias}$\n",
    "(Remember: it is (1.0 + 0.M) because, with normalized form, only the fractional part of the mantissa needs to be stored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floating Point Addition\n",
    "\n",
    "Add the following two decimal numbers in scientific notation:\n",
    "$$8.70 \\times 10^{-1}$$ with $$9.95 \\times 10^1$$\n",
    "\n",
    "1. Rewrite the smaller number such that its exponent matches with the exponent of the larger number.\n",
    "$$8.70 \\times 10^{-1} = 0.087 \\times 10^1$$\n",
    "\n",
    "2. Add the mantissas\n",
    "$$9.95 + 0.087 = 10.037$$ and write the sum $$10.037 \\times 10^1$$\n",
    "\n",
    "3. Put the result in Normalized Form\n",
    "$$10.037 \\times 10^1 = 1.0037 \\times 10^2$$ (shift mantissa, adjust exponent) check for overflow/underflow of the exponent after normalization\n",
    "\n",
    "4. Round the result\n",
    "If the mantissa does not fit in the space reserved for it, it has to be rounded off.\n",
    "\n",
    "For Example: If only 4 digits are allowed for mantissa\n",
    "\n",
    "$1.0037 \\times 10^2$ ===> $1.004 \\times 10^2$\n",
    "\n",
    "(only have a hidden bit with binary floating point numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example addition in binary\n",
    "\n",
    "Perform $0.5 + (-0.4375)$\n",
    "\n",
    "$$0.5 = 0.1 \\times 2^0 = 1.000 \\times 2^{-1} \\text{(normalised)}$$ \n",
    "\n",
    "$$-0.4375 = -0.0111 \\times 2^0 = -1.110 \\times 2^{-2} \\text{(normalised)}$$\n",
    "\n",
    "Rewrite the smaller number such that its exponent matches with the exponent of the larger number.\n",
    "$$-1.110 \\times 2^{-2} = -0.1110 \\times 2^{-1}$$\n",
    "\n",
    "Add the mantissas:\n",
    "$$1.000 \\times 2^{-1} + -0.1110 \\times 2^{-1} = 0.001 \\times 2^{-1}$$\n",
    "\n",
    "Normalise the sum, checking for overflow/underflow:\n",
    "$$0.001 \\times 2^{-1} = 1.000 \\times 2^{-4}$$\n",
    "\n",
    "$-126 <= -4 <= 127$ ===> No overflow or underflow\n",
    "\n",
    "Round the sum:\n",
    "- The sum fits in 4 bits so rounding is not required\n",
    "\n",
    "Check:\n",
    "- $1.000 \\times 2^{-4} = 0.0625$ which is equal to $0.5 - 0.4375$\n",
    "\n",
    "Correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floating Point Multiplication\n",
    "\n",
    "Multiply the following two numbers in scientific notation by hand:\n",
    "\n",
    "$$1.110 \\times 10^{10} \\times 9.200 \\times 10^{-5}$$\n",
    "\n",
    "Add the exponents to find\n",
    "- New Exponent $= 10 + (-5) = 5$\n",
    "\n",
    "If we add biased exponents, bias will be added twice. Therefore we need to subtract it once to compensate:\n",
    "$$(10 + 127) + (-5 + 127) = 259$$\n",
    "\n",
    "$259 - 127 = 132$ which is $(5 + 127) =$ biased new exponent\n",
    "\n",
    "Multiply the mantissas\n",
    "$$1.110 \\times 9.200 = 10.212000$$\n",
    "\n",
    "Can only keep three digits to the right of the decimal point, so the result is\n",
    "\n",
    "$$10.212 \\times 10^5$$\n",
    "\n",
    "Normalize the result\n",
    "$$1.0212 \\times 10^6$$\n",
    "\n",
    "Round it\n",
    "$$1.021 \\times 10^6$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example multiplication in binary:\n",
    "\n",
    "$$1.000 \\times 2^{-1} \\times -1.110 \\times 2^{-2}$$\n",
    "\n",
    "1. Add the biased exponents\n",
    "$(-1 + 127) + (-2 + 127) - 127 = 124$ ===> $(-3 + 127)$\n",
    "\n",
    "2. Multiply the mantissas\n",
    "\n",
    "$\\hspace{46pt}1.000$<br>\n",
    "$\\hspace{40pt}\\times 1.110$<br>\n",
    "----------------------------<br>\n",
    "$\\hspace{62pt}0000$<br>\n",
    "$\\hspace{57pt}1000$<br>\n",
    "$\\hspace{53pt}1000$<br>\n",
    "$\\hspace{42pt}+1000$<br>\n",
    "----------------------------<br>\n",
    "$\\hspace{47pt}1110000$ ===> $1.110000$\n",
    "\n",
    " - The product is $1.110000 \\times 2^{-3}$\n",
    " - Need to keep it to 4 bits $1.110 \\times 2^{-3}$\n",
    "\n",
    "3. Normalize (already normalized)\n",
    " - At this step check for overflow/underflow by making sure that\n",
    "\n",
    "$$-126 <= \\text{Exponent} <= 127$$\n",
    "\n",
    "$$1 <= \\text{Biased Exponent} <= 254$$\n",
    "\n",
    "4. Round the result (no change)\n",
    "5. Adjust the sign. Since the original signs are different, the result will be negative\n",
    "\n",
    "$$-1.110 \\times 2^{-3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use numpy.isclose rather than equality for floating point comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.isclose.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ba9b04f098e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Repeating the experiment above\n",
    "\n",
    "x = np.float32(1)\n",
    "y = np.float32(1/3)\n",
    "\n",
    "assert x == 3*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(x, 3*y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real world example of floating point bugs\n",
    "\n",
    "### Real world example: Patriot missile failure due to magnification of roundoff error\n",
    "#### https://en.wikipedia.org/wiki/Round-off_error#Real_world_example:_Patriot_missile_failure_due_to_magnification_of_roundoff_error\n",
    "\n",
    "American Patriot missile: On 25 February 1991, during the Gulf War, an American Patriot missile battery in Dharan, Saudi Arabia, failed to intercept an incoming Iraqi Scud missile. The Scud struck an American Army barracks and killed 28 soldiers. A report of the General Accounting office, GAO/IMTEC-92-26, entitled Patriot Missile Defense: Software Problem Led to System Failure at Dhahran, Saudi Arabia reported on the cause of the failure. It turns out that the cause was an inaccurate calculation of the time since boot due to computer arithmetic errors. Specifically, the time in tenths of second as measured by the system's internal clock was multiplied by 1/10 to produce the time in seconds. This calculation was performed using a 24-bit fixed point register. In particular, the value 1/10, which has a non-terminating binary expansion, was chopped at 24 bits after the radix point. The small chopping error, when multiplied by the large number giving the time in tenths of a second, led to a significant error. Indeed, the Patriot battery had been up around 100 hours, and an easy calculation shows that the resulting time error due to the magnified chopping error was about 0.34 seconds. Multiplying by the number of tenths of a second in $100$ hours gives $0.000000095\\times 100\\times 60\\times 60\\times 10=0.34$). A Scud travels at about 1676 meters per second, and so travels more than half a kilometer in this time. This was far enough that the incoming Scud was outside the \"range gate\" that the Patriot tracked. Ironically, the fact that the bad time calculation had been improved in some parts of the code, but not all, contributed to the problem, since it meant that the inaccuracies did not cancel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
