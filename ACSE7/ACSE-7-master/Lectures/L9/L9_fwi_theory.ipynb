{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full-waveform inversion - Theory\n",
    "\n",
    "Full-waveform inversion (FWI) is a computational scheme for generating high-resolution, high-fidelity models of physical properties using finite-frequency waves. The waves could be electromagnetic, acoustic, elastic or of various other kinds. The method is used in medical imaging of soft tissues, in non-destructive testing, in petroleum exploration, in earthquake seismology, and to image the interior of the Sun. FWI is a form of tomography, but conventional tomography assumes that energy travels along infinitely thin geometric ray paths, that there are no finite-frequency wave effects, and that it is necessary only to fit a single amplitude or travel-time for each source-and-receiver pair. In contrast, FWI attempts to fully account for the finite wavelength of the observed signals, and it seeks to explain the detailed waveforms of the recorded data.\n",
    "\n",
    "Like other simpler forms of tomography, FWI is a local, iterated inversion scheme that successively improves a starting model. It does this by using the two-way wave equation to predict the observed data from a model, and then seeks to find a new model that minimises the differences between those predictions and the observed data; it attempts to match the raw observed data wiggle for wiggle. The computational effort required for FWI is large, but the resulting spatial resolution is much better than can be obtained by conventional tomography - it has only become economically feasible for three-dimensional models in the last ten years or so. The notation used is summarised at the end of these notes, together with definitions of the $L_2-norm$, the *gradient* and the *Hessian*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td> <img src=\"figures/survey-ship-diagram.png\" alt=\"Drawing\" style=\"width: 450px;\"/> </td>\n",
    "    <td> <img src=\"figures/Marmousi3D.png\" alt=\"Drawing\" style=\"width: 450px;\"/> </td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Left:** Sketch of offshore seismic survey. **Right:** Example model result for $v_p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The FWI algorithm\n",
    "\n",
    "The aim of FWI is find a model that minimises some measure of the misfit between a dataset predicted by a model and an observed dataset - this measure is called the *objective function*.\n",
    "\n",
    "A simple geometric analogy, in which the model has just two parameters, is to regard the misfit as being represented by the local height of a two-dimensional error surface, and the two model parameters as representing the $x$ and $y$-coordinates of a point on this surface. FWI then involves starting at some point on this surface, and trying to find the bottom of the deepest valley by heading downhill in a sequence of finite steps. To do this, we have to discover which way is downhill, and how far to step. In real FWI, the model has not just two parameters, but many millions, but the analogy is still appropriate. The algorithm proceeds as follows:\n",
    "1. Calculate the direction of the local gradient $\\nabla_\\mathbf{m}$ of the objective function f with respect to the model parameters - this points uphill\n",
    "    - Using the *starting model* $\\mathbf{m}$ and a known *source* $\\mathbf{s}$, calculate the forward *wavefield* $\\mathbf{u}$ everywhere in the model including the *predicted data* $\\mathbf{p}$ at the receivers.\n",
    "    - At the receivers, subtract the observed data d from the predicted data to obtain the *residual data* $\\delta\\mathbf{d}$.\n",
    "    - Treating the receivers as virtual sources, back-propagate the residual data into the model, to generate the residual wavefield $\\delta\\mathbf{u}$.\n",
    "    - Scale the residual wavefield by the local slowness $1/c$, and differentiate it twice in time.\n",
    "    - At every point in the model, cross-correlate the forward and scaled residual wavefields, and take the zero lag in time to generate the *gradient* for one source.\n",
    "    - Do this for every source, and stack together the results to make the global gradient.\n",
    "2. Find the step length - how far is the bottom of the hill?\n",
    "    - Take a small step and a larger step directly downhill, and calculate the objective function at the current model and in these two new models.\n",
    "    - Assume a linear relationship between changes in the model and changes in the residual data so that there will be a parabolic relationship between changes in the model and changes in the objective function, then fit a parabola through these three points.\n",
    "    - The lowest point on this parabola represents the optimal step length (assuming a locally linear relationship).\n",
    "    - Step downhill by the required amount, and update the model.\n",
    "3. Do it all over again\n",
    "    - Use the new model as the starting model, and repeat steps 1. and 2.\n",
    "    - Repeat this process until the model is 'good enough', that is the model is no longer changing (to some numerical tolerance), or we run out of time, money or patience.\n",
    "\n",
    "This is the basic algorithm. There are several ways to enhance and improve it, but nearly all of these involve a greater computational cost (which is already high)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Wave Equation\n",
    "\n",
    "The wave equation is a simplified model for, i.e. the displacement of a vibrating\n",
    "string (approx. 1D), a membrane (such as a drum skin, approx. 2D) or an elastic solid in 3D (the situation relevant to FWI). That is, the main physics the wave equation is attempting to capture is, broadly speaking, the transfer through space of oscillatory energy (vibrations in time).\n",
    "\n",
    "The simplest wave equation that is commonly used in FWI is:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\frac{1}{c^2}\\frac{\\partial^2 u}{\\partial t^2}-\\nabla^2 u = s,\n",
    "\\label{eq:we0} \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "where $u$ is the propagating wavefield measured using some appropriate material property (for example electric field in an EM wave or acoustic pressure in an acoustic wave), $s$ is the driving source that produces the wavefield, and $c$ is the wave speed. Both $u$ and $s$ vary in space and time, and c varies in space. This equation applies to small-amplitude linear waves propagating within an inhomogeneous, isotropic, constant-density, non-attenuating, non-dispersive, fluid medium. It is relatively straightforward to add variable density, shear\n",
    "strength, attenuation, anisotropy, dispersion, polarisation and other physical effects to this simple wave equation; these effects change the detailed equations and numerical complexity, but not the general approach.\n",
    "\n",
    "### Simplified derivation of the 1D wave-equation\n",
    "\n",
    "For a simple derivation of the 1D acoustic wave equation let us focus on an isotropic and homogeneous elastic string, where $u(x, t)$ describes displacement or 'height' from the position of rest at position $x$ and time $t$. We consider a\n",
    "small subinterval $[x_1, x_2]$. The total acceleration, $a$, in the '$u$'-direction within this interval is\n",
    "\n",
    "\\begin{equation}\n",
    "   a=\\partial^2\\int_{x_1}^{x^2}u(x,t)\\mathrm{d}t=\\int_{x_1}^{x^2}u_{tt}(x,t)\\mathrm{d}x.\n",
    "\\label{eq:sd0} \\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "The total force acting on this interval of the string is the net force of the forces\n",
    "acting at the points $x_1$ and $x_2$. The force $F=F(u)$ will be some function\n",
    "of $u$. By Newtonâ€™s law, force equals acceleration for unit mass and hence\n",
    "\n",
    "\\begin{equation}\n",
    "  a = F(u(x_2,t))-F(u(x_1,t))=\\int_{x_1}^{x_2}F_{x}(u(x,t))\\mathrm{d}x.\n",
    "  \\label{eq:sd1} \\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "We are now required to make some assumptions. Let us assume that the force $F$ is proportional to the slope of the string with a proportionality factor $c^2$ (can be justified for small displacements). Hence\n",
    "\n",
    "\\begin{equation}\n",
    "  F(u) \\approx c^2 u_x.\n",
    "  \\label{eq:sd2} \\tag{4}\n",
    "\\end{equation}\n",
    "\n",
    "Combining the above yields\n",
    "\n",
    "\\begin{equation}\n",
    "  \\int_{x_1}^{x_2}(u_{tt}-c^2 u_{xx})\\mathrm{d}x=0.\n",
    "  \\label{eq:sd3} \\tag{5}\n",
    "\\end{equation}\n",
    "\n",
    "Since this holds for an arbitrary interval $[x_1, x_2]$, we must have that\n",
    "\n",
    "\\begin{equation}\n",
    "  \\frac{1}{c^2}u_{tt}=c^2 u_{xx},\n",
    "  \\label{eq:sd4} \\tag{6}\n",
    "\\end{equation}\n",
    "\n",
    "which is the 1D wave equation. Similar arguments (albeit using vector calculus) can be made to derive the corresponding wave equation in two or three dimensions.\n",
    "\n",
    "### Other forms of the wave equation\n",
    "\n",
    "More general forms of the wave equation can be written as\n",
    "\n",
    "\\begin{equation}\n",
    "  \\rho(\\mathbf{x})\\frac{\\partial^2 \\mathbf{u}}{\\partial t^2}(\\mathbf{x},t)-\\nabla\\cdot\\mathbf{\\sigma}(\\mathbf{x},t)=\\mathbf{f}(\\mathbf{x},t),\n",
    "  \\label{eq:awe0} \\tag{7}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{u}(\\mathbf{x},t)$ is the displacement field and $\\rho(\\mathbf{x})$, $\\mathbf{\\sigma}(\\mathbf{x},t)$, and $\\mathbf{f}(\\mathbf{x},t)$ represent the material density, stress tensor and an external force density respectively. Depending on the fidelity of model we wish to implement, $\\mathbf{\\sigma}(\\mathbf{x},t)$ can take on many different forms (the simplest, as we'll see below, resulting in the acoustic wave equation defined above). For example, the acoustic wave equation only accounts for the propagation of *pressure waves* (P-waves) but the propagation of *shear waves* (S-waves) is also important in many physical problems. In the *elastic wave equation*, which accounts for the propagation of both P- and S-waves (i.e. both longitudinal and transverse motions) the stress tensor can be written as (dropping function dependencies for conciseness)\n",
    "\n",
    "\\begin{equation}\n",
    "  \\sigma_{ij}=\\sum_{k,l=1}^{3}(\\lambda\\delta_{ij}\\delta_{kl}+\\mu\\delta_{ik}\\delta_{jl}+\\mu\\delta_{il}\\delta_{jk})\\varepsilon_{kl},\n",
    "  \\label{eq:awe1} \\tag{8}\n",
    "\\end{equation}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{equation}\n",
    "  \\varepsilon_{ij}=\\frac{1}{2}(\\partial_{i}u_{j}+\\partial_{j}u_{i})\n",
    "  \\label{eq:awe2} \\tag{9}\n",
    "\\end{equation}\n",
    "\n",
    "and $\\lambda$ and $\\mu$ and known as *Lame parameters* (which are determined by the physical properties of the isotropic homogeneous elastic medium). Note that in the formulations introduced so far, energy is not dissipated - one formulation in which energy is dissipated is know as the *viscoelastic wave equation*. We will not discuss this formulation here, but for interested readers details regarding viscoelastic formulations (along with acoustic and elastic) and details regarding FWI in general can be found in the book entitled **Full Seismic Waveform Modelling and Inversion** by **Andreas Fichtner**.\n",
    "\n",
    "In the fluid regions of the Earth (e.g. oceans and outer core) the shear modulus $\\mu$ (one of the *Lame parameters*) is effectively zero. In such cases the stress tensor reduces to\n",
    "\n",
    "\\begin{equation}\n",
    "  \\sigma_{ij} = \\kappa\\delta_{ij}\\nabla\\cdot\\mathbf{u}=-p\\delta_{ij},\n",
    "  \\label{eq:awe3} \\tag{10}\n",
    "\\end{equation}\n",
    "\n",
    "where we have introduced the scalar pressure $p:=-\\kappa\\nabla\\cdot\\mathbf{u}$ and $\\kappa$ ($=\\lambda+\\frac{2}{3}$) is the *bulk modulus* (which has a more straightforward physical interpretation). Hence, $\\eqref{eq:awe0}$ reduces to\n",
    "\n",
    "\\begin{equation}\n",
    "  \\rho\\ddot{\\mathbf{u}}+\\nabla p = \\mathbf{f}.\n",
    "  \\label{eq:awe4} \\tag{11}\n",
    "\\end{equation}\n",
    "\n",
    "(Note: $\\ddot{f}\\equiv\\frac{\\partial^2 f}{\\partial t^2}$.) Dividing by the density $\\rho$ and taking the divergence gives\n",
    "\n",
    "\\begin{equation}\n",
    "  \\nabla\\cdot\\ddot{\\mathbf{u}}+\\nabla\\cdot(\\rho^{-1}\\nabla p) = \\nabla\\cdot(\\rho^{-1}\\mathbf{f}).\n",
    "  \\label{eq:awe5} \\tag{12}\n",
    "\\end{equation}\n",
    "\n",
    "Using our definition of pressure we can then eliminate $\\mathbf{u}$ leaving\n",
    "\n",
    "\\begin{equation}\n",
    "  \\kappa^{-1}\\ddot{p}-\\nabla\\cdot(\\rho^{-1}\\nabla p) = -\\nabla\\cdot(\\rho^{-1}\\mathbf{f}).\n",
    "  \\label{eq:awe6} \\tag{13}\n",
    "\\end{equation}\n",
    "\n",
    "Provided density varies much slower than the pressure field $p$ and the source term $\\mathbf{f}$ we can further simply to obtain\n",
    "\n",
    "\\begin{equation}\n",
    "  \\ddot{p}-v_p^2\\nabla^2p=-v_p^2\\nabla\\cdot\\mathbf{f},\n",
    "  \\label{eq:awe7} \\tag{14}\n",
    "\\end{equation}\n",
    "\n",
    "with the *acoustic wave speed* $v_a:=\\sqrt{\\frac{\\kappa}{\\rho}}$. This is of course the 'main' equation of FWI introduced earlier when we let the wavefield $u=p$, the wave speed $c=v_p$ and 'abstracting away' any intricacies in the source term such we have simply $-v_p^2\\nabla\\cdot\\mathbf{f}=s$.\n",
    "\n",
    "\n",
    "### Matrix form\n",
    "\n",
    "The wave equation represents a linear relationship between a wavefield $u$ and the source $s$ that generates the wavefield. After discretisation (with for example finite differences) we can therefore write $\\eqref{eq:we0}$ as a matrix equation\n",
    "\n",
    "\\begin{equation}\n",
    "  \\mathbf{A}\\mathbf{u}=\\mathbf{s},\n",
    "\\label{eq:we1} \\tag{15}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{u}$ and $\\mathbf{s}$ are column vectors that represent the source and wavefield at discrete points\n",
    "in space and time, and $\\mathbf{A}$ is a matrix that represents the discrete numerical implementation of the operator\n",
    "\n",
    "\\begin{equation}\n",
    "  \\frac{1}{c^2}\\frac{\\partial^2}{\\partial t^2}-\\nabla^2.\n",
    "\\label{eq:we3} \\tag{16}\n",
    "\\end{equation}\n",
    "\n",
    "Although the wave equation represents a linear relationship between $u$ and $s$, it also represents a non-linear relationship between a model $\\mathbf{m}$ and wavefield $\\mathbf{u}$. Thus we can also write the wave equation as\n",
    "\n",
    "\\begin{equation}\n",
    "  G(\\mathbf{m})=\\mathbf{u}.\n",
    "\\label{eq:we4} \\tag{17}\n",
    "\\end{equation}\n",
    "\n",
    "Here $\\mathbf{m}$ is a column vector that contains the model parameters. Commonly these will be the values of $c$ at every point in the model, but they may be any set of parameters that is sufficient to describe the model, for example slownesses $1/c$. Note that in equation $\\eqref{eq:we4}$ $G$ is not a matrix; it is a (non-linear) function that describes how to calculate a wavefield $\\mathbf{u}$ given a model $\\mathbf{m}$.\n",
    "\n",
    "Note that the form of matrix $\\mathbf{A}$ depends upon both the model properties and the details of the numerical implementation, and that the form of the function $G$ depends upon the source and the acquisition geometry. The form of $\\mathbf{A}$ does not depend upon the source and the form of $G$ does not depend upon the model.\n",
    "\n",
    "It is common in FWI to construct the numerical wave equation in $\\eqref{eq:we1}$ such that the matrix\n",
    "$\\mathbf{A}$ represents a wave travelling forward in time, and its transpose represents a wave travelling\n",
    "backwards in time. This is not essential, but it is often straightforward to achieve, in which\n",
    "case it simplifies the numerics of FWI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Objective Function\n",
    "\n",
    "The central purpose of FWI is to find a physical model of the wave-transmitting medium that\n",
    "minimises the difference between an observed dataset and the same dataset as predicted by\n",
    "the model. Consequently we need a means to measure this difference. There are many ways\n",
    "to do this, but the most common is a *least-squares* formulation where we seek to minimise the\n",
    "sum of the squares of the differences between the two datasets over all sources and receivers,\n",
    "and over all times. That is, we seek to find a model that minimises the square of the $L_2-norm$\n",
    "of the *data residuals*.\n",
    "\n",
    "The $L_2-norm$ expresses the misfit between the two datasets as a single number. This number\n",
    "is variously called the *cost function*, the *objective function*, the *misfit function*, or just the\n",
    "*functional*. It is typically given the symbol $f$. It is a real positive scalar quantity, and it is\n",
    "a function of the model $\\mathbf{m}$. In practice, a factor of a half is often included in the definition\n",
    "of the objective function to 'simplify' the formulation (as we will see later). Define:\n",
    "\n",
    "\\begin{equation}\n",
    "  f(\\mathbf{m})=\\frac{1}{2}||\\mathbf{p}-\\mathbf{d}||^2=\\frac{1}{2}||\\delta\\mathbf{d}||^2=\\frac{1}{2}\\delta\\mathbf{d}^{T}\\delta\\mathbf{d}=\\frac{1}{2}\\sum_{n_s}\\sum_{n_r}\\sum_{n_t}|p-d|^2,\n",
    "\\label{eq:oe0} \\tag{18}\n",
    "\\end{equation}\n",
    "\n",
    "where $n_s$, $n_r$ and $n_t$ are the number of sources, receivers and time samples in the data set,\n",
    "and $\\mathbf{d}$ and $\\mathbf{p}$ are the observed and predicted datasets.\n",
    "\n",
    "To minimise this function with respect to the model parameters $\\mathbf{m}$, we have to differentiate\n",
    "$f$ with respect to $\\mathbf{m}$, set the differentials equal to zero, and solve for $\\mathbf{m}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Inversion\n",
    "\n",
    "FWI is a local iterative inversion scheme. It begins from a starting model $\\mathbf{m}_0$ that is\n",
    "assumed to be sufficiently close to the true model, and it seeks to make a series of step-wise\n",
    "improvements to this model which successively reduce the objective function towards zero.\n",
    "Thus, we need to consider the objective function for a starting model $\\mathbf{m}_0$ and a new model\n",
    "$\\mathbf{m}=\\mathbf{m}_0+\\delta\\mathbf{m}$.\n",
    "\n",
    "Recall the Taylor series, truncated to second order, for a scalar function of a single *scalar*\n",
    "variable is\n",
    "\n",
    "\\begin{equation}\n",
    "  f(x) = f(x_0+\\delta x)=f(x_0)+\\delta x\\frac{\\mathrm{d} f}{\\mathrm{d} x}\\biggr|_{x=x_0}+\\frac{1}{2}\\delta x^2 \\frac{\\mathrm{d}^2f}{\\mathrm{d}x^2}\\biggr|_{x=x_0}+\\mathcal{O}(\\delta x^3).\n",
    "  \\label{eq:li0} \\tag{19}\n",
    "\\end{equation}\n",
    "\n",
    "For a scalar function of a *vector*, the analogous expression is\n",
    "\n",
    "\\begin{equation}\n",
    "  f(\\mathbf{m}) = f(\\mathbf{m}_0+\\delta\\mathbf{m})=f(\\mathbf{m}_0)+\\delta\\mathbf{m}^T\\frac{\\partial f}{\\partial \\mathbf{m}}\\biggr|_{\\mathbf{m}=\\mathbf{m}_0}+\\frac{1}{2}\\delta\\mathbf{m}^T \\frac{\\partial^2f}{\\partial \\mathbf{m}^2}\\biggr|_{\\mathbf{m}=\\mathbf{m}_0}\\delta\\mathbf{m}+\\mathcal{O}(\\delta \\mathbf{m}^3).\n",
    "  \\label{eq:li1} \\tag{20}\n",
    "\\end{equation}\n",
    "\n",
    "Now we must differentiate this equation with respect to $\\mathbf{m}$, and set the result to zero in order to\n",
    "minimise $f$ with respect to $\\mathbf{m}_0+\\delta\\mathbf{m}$. Note that differentiating with respect to $\\mathbf{m}$ is the same as differentiating with respect to $\\delta\\mathbf{m}$ because $\\mathbf{m}_0$ is constant. Note also that $f$, $\\partial f\\partial\\mathbf{m}$ and $\\partial^2 f\\partial\\mathbf{m}^2$, evaluated at $\\mathbf{m}=\\mathbf{m}_0$, do not depend upon $\\delta\\mathbf{m}$. Thus, when we differentiate equation with respect to $\\mathbf{m}$, we obtain\n",
    "\n",
    "\\begin{equation}\n",
    "  \\frac{\\partial f}{\\partial \\mathbf{m}}\\biggr|_{\\mathbf{m}=\\mathbf{m}_0+\\delta \\mathbf{m}} = \\frac{\\partial f}{\\partial \\mathbf{m}}\\biggr|_{\\mathbf{m}=\\mathbf{m}_0}+\\left(\\frac{1}{2}\\delta\\mathbf{m}^T \\frac{\\partial^2f}{\\partial \\mathbf{m}^2}\\biggr|_{\\mathbf{m}=\\mathbf{m}_0}\\right)^T+\\frac{\\partial^2f}{\\partial \\mathbf{m}^2}\\biggr|_{\\mathbf{m}=\\mathbf{m}_0}\\delta\\mathbf{m}+....\n",
    "  \\label{eq:li2} \\tag{21}\n",
    "\\end{equation}\n",
    "\n",
    "Setting this equal to zero, and combining the two middle terms, gives\n",
    "\n",
    "\\begin{equation}\n",
    "  \\frac{\\partial f}{\\partial \\mathbf{m}}\\biggr|_{\\mathbf{m}=\\mathbf{m}_0}+\\frac{\\partial^2f}{\\partial \\mathbf{m}^2}\\biggr|_{\\mathbf{m}=\\mathbf{m}_0}\\delta\\mathbf{m}+\\mathcal{O}(\\delta\\mathbf{m}^2)=0.\n",
    "  \\label{eq:li3} \\tag{22}\n",
    "\\end{equation}\n",
    "\n",
    "Neglecting second-order terms, and rearranging, gives an expression for the update to the\n",
    "model $\\delta\\mathbf{m}$:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\delta\\mathbf{m} \\approx - \\left(\\frac{\\partial^2 f}{\\partial\\mathbf{m}^2}\\right)^{-1}\\frac{\\partial f}{\\partial\\mathbf{m}} \\equiv -\\mathbf{H}^{-1}\\nabla_{\\mathbf{m}}f.\n",
    "\\label{li4} \\tag{23}\n",
    "\\end{equation}\n",
    "\n",
    "Here $\\nabla_{\\mathbf{m}}f$ is the *gradient* of the objective function $f$ with respect to the model parameters,\n",
    "and $\\mathbf{H}$ is the *Hessian* matrix of second differentials, both evaluated at $\\mathbf{m}_0$.\n",
    "\n",
    "If the model has $n$ parameters, then the gradient is a column vector of length $n$, and the\n",
    "Hessian is an $n \\times n$ symmetric matrix. Methods that solve the inversion problem using\n",
    "equation $\\eqref{li4}$ directly are called *Newton* methods. Methods that use equation $\\eqref{li4}$ with a\n",
    "'reasonable' approximation to the Hessian are called Gauss-Newton or quasi-Newton methods\n",
    "depending upon how the approximation is formulated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steepest Descent\n",
    "\n",
    "If the number of model parameters $n$ is large, calculating the Hessian is a major\n",
    "undertaking, and inverting it is not normally computationally feasible. Consequently the\n",
    "method that is typically used is to replace the inverse of the Hessian in equation ([23](#mjx-eqn-li4)) by a\n",
    "simple scalar $\\alpha$; this scalar is called the step length. We now have\n",
    "\n",
    "\\begin{equation}\n",
    "  \\delta\\mathbf{m} = -\\alpha\\frac{\\partial f}{\\partial \\mathbf{m}} = -\\alpha\\nabla_{\\mathbf{m}}f .\n",
    "  \\tag{24}\n",
    "\\end{equation}\n",
    "\n",
    "The method that uses this approach is called the method of *steepest descent*, and in its\n",
    "simplest form it consists of the following steps:\n",
    "1. start from a model $\\mathbf{m}_0$,\n",
    "2. evaluate the gradient of the objective function, $\\nabla_{\\mathbf{m}}f$, for the current model,\n",
    "3. find the step length $\\alpha$,\n",
    "4. subtract $\\alpha$ times the gradient from the current model to obtain a new model,\n",
    "5. iterate from step 2 using the new model until the objective function is sufficiently small (or we run out of patience).\n",
    "\n",
    "To implement this, we need a method of calculating the local gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the gradient\n",
    "\n",
    "In principle, we could find the gradient by perturbing each of the model parameters in turn,\n",
    "and calculating what happens to the objective function each time. For $n$ model parameters,\n",
    "that would require $n+1$ modelling runs, and this is not computationally feasible. Fortunately\n",
    "there is a faster way using a solution to the *adjoint* problem.\n",
    "\n",
    "First, write the gradient in terms of the residual data $\\delta\\mathbf{d}=\\mathbf{p}-\\mathbf{d}$:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\nabla_{\\mathbf{m}}f=\\frac{\\partial f}{\\partial \\mathbf{m}}=\\frac{\\partial}{\\partial \\mathbf{m}}\\left(\\frac{1}{2}\\delta\\mathbf{d}^T\\delta\\mathbf{d}\\right)=\\frac{\\partial (\\mathbf{p}-\\mathbf{d})^T}{\\partial \\mathbf{m}}\\delta\\mathbf{d}=\\left(\\frac{\\partial \\mathbf{p}}{\\partial \\mathbf{m}}\\right)^T\\delta\\mathbf{d}.\n",
    "  \\label{eq:rw0} \\tag{25}\n",
    "\\end{equation}\n",
    "\n",
    "Now, write the wave equation for a dataset $\\mathbf{p}$ generated by a source $\\mathbf{s}$ as\n",
    "\n",
    "\\begin{equation}\n",
    "  \\mathbf{Au}=\\mathbf{s},\n",
    "  \\label{eq:rwe1} \\tag{26}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{p}$ is the subset of the full wavefield $\\mathbf{u}$ that is located at the receiver positions.\n",
    "Mathematically, we can extract the data at the receivers from the data everywhere in the\n",
    "model simply by using a diagonal *restriction* matrix $\\mathbf{R}$ that has non-zero unit values only\n",
    "where there exists observed data. That is\n",
    "\n",
    "\\begin{equation}\n",
    "  \\mathbf{p}=\\mathbf{Ru}.\n",
    "  \\label{eq:rwe2} \\tag{27}\n",
    "\\end{equation}\n",
    "\n",
    "Now, differentiate equation $\\eqref{eq:rwe2}$ with respect to $\\mathbf{m}$ to obtain\n",
    "\n",
    "\\begin{equation}\n",
    "  \\frac{\\partial\\mathbf{A}}{\\partial\\mathbf{m}}\\mathbf{u}+\\mathbf{A}\\frac{\\partial\\mathbf{u}}{\\partial\\mathbf{m}}=\\frac{\\partial\\mathbf{s}}{\\partial\\mathbf{m}}=0,\n",
    "  \\label{eq:rwe3} \\tag{28}\n",
    "\\end{equation}\n",
    "\n",
    "which is equal to zero because the source \\mathbf{s} does not depend upon the model \\mathbf{m}.\n",
    "Rearranging gives\n",
    "\n",
    "\\begin{equation}\n",
    "  \\frac{\\partial\\mathbf{u}}{\\partial\\mathbf{m}}=-\\mathbf{A}^{-1}\\frac{\\partial\\mathbf{A}}{\\partial\\mathbf{m}}\\mathbf{u},\n",
    "  \\label{eq:rwe4} \\tag{29}\n",
    "\\end{equation}\n",
    "\n",
    "and pre-multiplying $\\eqref{eq:rwe4}$ by the matrix $\\mathbf{R}$ extracts the wavefield only at those points where\n",
    "we have data.\n",
    "\n",
    "So now, to find the variation of the data with the model, we have\n",
    "\n",
    "\\begin{equation}\n",
    "  \\frac{\\partial\\mathbf{p}}{\\partial\\mathbf{m}}=\\mathbf{R}\\frac{\\partial\\mathbf{u}}{\\partial\\mathbf{m}}=-\\mathbf{R}\\mathbf{A}^{-1}\\frac{\\partial\\mathbf{A}}{\\partial\\mathbf{m}}\\mathbf{u}.\n",
    "  \\label{eq:rwe5} \\tag{30}\n",
    "\\end{equation}\n",
    "\n",
    "Substituting $\\eqref{eq:rwe5}$ into $\\eqref{eq:rw0}$ and rearranging results in the following expression for the gradient\n",
    "\n",
    "\\begin{equation}\n",
    "  \\nabla_{\\mathbf{m}}f=-\\mathbf{u}^T\\left(\\frac{\\partial \\mathbf{A}}{\\partial \\mathbf{m}}\\right)^T(\\mathbf{A^{-1}})^T\\mathbf{R}^T\\delta\\mathbf{d}.\n",
    "  \\label{eq:rwe6} \\tag{31}\n",
    "\\end{equation}\n",
    "\n",
    "Therefore, to find the gradient, we must calculate the forward wavefield $\\mathbf{u}$, differentiate\n",
    "the numerical operator $\\mathbf{A}$ with respect to the model parameters (this is an operation that\n",
    "we can do analytically), and we must also compute the final term $(\\mathbf{A}^{-1})^T\\mathbf{R}^T\\delta\\mathbf{d}$. We must multiply these terms together at all times, and for all sources, and sum these together to\n",
    "give a value corresponding to each parameter within the model; typically this means one\n",
    "value of $\\nabla_{\\mathbf{m}}f$ at each grid point within the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the expression for the gradient\n",
    "\n",
    "The final term in ([31](#mjx-eqn-eq:rwe6)) represents the back-propagation of the residual data $\\delta\\mathbf{d}$. This can be seen by writing the term as\n",
    "\n",
    "\\begin{equation}\n",
    "  (\\mathbf{A^{-1}})^T\\mathbf{R}^T\\delta\\mathbf{d}=\\delta\\mathbf{u},\n",
    "  \\label{eq:ig0} \\tag{32}\n",
    "\\end{equation}\n",
    "\n",
    "which can be rearranged to give\n",
    "\n",
    "\\begin{equation}\n",
    "  \\mathbf{A}^T\\delta\\mathbf{u}=\\mathbf{R}^T\\delta\\mathbf{d}.\n",
    "  \\label{eq:ig1} \\tag{33}\n",
    "\\end{equation}\n",
    "\n",
    "The matrix $\\mathbf{R}$ represents the operation of extracting the wavefield at the receivers; consequently, its transpose represents the operation of re-injecting the wavefield at the receivers\n",
    "back into the model. Equation $\\eqref{eq:ig1}$ then simply describes a wavefield $\\delta\\mathbf{u}$ that is generated by a (virtual) source $\\delta\\mathbf{d}$ located at the receivers, and that is propagated by the operator $\\mathbf{A}^T$ which is the *adjoint* of the operator in the original wave equation. So the term that we\n",
    "need to compute in ([31](#mjx-eqn-eq:rwe6)) is the wavefield generated by a *modified* wave equation with\n",
    "the data residuals used as sources.\n",
    "\n",
    "Typically, to simplify the computations in the time domain, the numerical operator $\\mathbf{A}$ is\n",
    "designed such that it is symmetrical (i.e. self adjoint) in space, and such that its transpose\n",
    "is equivalent to a back propagation in time. Formulating the problem this way allows the\n",
    "use of the same code to calculate both $\\mathbf{A}$ and $\\mathbf{A}^T$ , where $\\mathbf{A}$ propagates a wavefield forward in time, and $\\mathbf{A}^T$ propagates a wavefield backward in time.\n",
    "\n",
    "So now, to calculate the gradient, we must find\n",
    "\n",
    "\\begin{equation}\n",
    "  \\nabla_{\\mathbf{m}}f=-\\mathbf{u}^{T}\\left(\\frac{\\partial\\mathbf{A}}{\\partial\\mathbf{m}}\\right)^T\\delta\\mathbf{u},\n",
    "  \\label{eq:ig2} \\tag{34}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{u}$ is the calculated forward wavefield, $\\delta\\mathbf{u}$ represents the wavefield generated by back-propagating the data residuals, and the 'middle' can be calculated analytically.\n",
    "The expression for the gradient in $\\eqref{eq:ig2}$ represents the zero lag of the temporal cross\n",
    "correlation of the forward wavefield for a particular source with the back-propagated wavefield\n",
    "generated by the data residuals at each receiver for that source, calculated at every point\n",
    "in the model, and weighted and modified by an analytical expression that depends upon\n",
    "how the model $\\mathbf{m}$ and operator $\\mathbf{A}$ have been defined. Typically, in the time domain, this\n",
    "weighting and modification involves the double differential of the back-propagated wavefield\n",
    "with respect to time, and a scaling by the local value of the slowness.\n",
    "\n",
    "For one source, the gradient calculated this way requires only two modelling runs rather\n",
    "than the $n+1$ modelling runs that direct methods require. For multi-source datasets, the\n",
    "full gradient is a sum over all sources. In practical applications with real datasets, the wave equation will nearly always be modified in various ways to include additional physics, but this does not change the underlying\n",
    "approach. Several other numerical enhancements will normally also be incorporated into\n",
    "the basic FWI scheme. Simply ignoring the Hessian is a gross simplification and while it\n",
    "is not normally possible to incorporate its effects fully, there are several possibilities for\n",
    "approximating its effects - L-BFGS is widely used, as are conjugate gradients.\n",
    "\n",
    "Useful links:\n",
    "- **L-BFGS**: https://en.wikipedia.org/wiki/Limited-memory_BFGS\n",
    "- **Conjugate gradient**: https://en.wikipedia.org/wiki/Conjugate_gradient_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General notation and definitions\n",
    "\n",
    "|      Symbol   |  Definition  |\n",
    "|---------------|--------------|\n",
    "|   $\\mathbf{v}$  | column vector (bold lower case letter)|\n",
    "|      $||v||$    | Euclidean norm of $\\mathbf{v}$|\n",
    "| $\\mathbf{M}$ | matrix (bold capitalised letter)|\n",
    "| $\\mathbf{M}^T$ | transpose of $\\mathbf{M}$; if $\\mathbf{M}$ is real then $\\mathbf{M}^T$ is the *adjoint* of $\\mathbf{M}$ |\n",
    "| $\\mathbf{M}^{-1}$ | inverse of $\\mathbf{M}$ |\n",
    "| $\\mathbf{H}$ | Hessian matrix |\n",
    "| $\\mathcal{O}(.)$ | Terms of order $.$ and higher |\n",
    "| $x$ | scalar variable |\n",
    "| $\\delta x$ | infinitesimal perturbation to $x$ |\n",
    "| $\\nabla_{\\mathbf{x}}$ | gradient with respect to $\\mathbf{x}$, i.e. $\\left(\\frac{\\partial}{\\partial x_1},\\frac{\\partial}{\\partial x_1}, \\frac{\\partial}{\\partial x_2}, ..., \\frac{\\partial}{\\partial x_n}\\right)^T$ |\n",
    "| $|_{\\mathbf{x}=\\mathbf{x}_0}$ | evaluation of a function of $\\mathbf{x}$ at $\\mathbf{x}_0$ |\n",
    "\n",
    "## FWI notation and definitions\n",
    "\n",
    "|      Symbol   |  Definition  |\n",
    "|---------------|--------------|\n",
    "| $\\alpha$ | step length |\n",
    "| $\\mathbf{A}$ | operator resulting from the numerical discretisation of the wave-equation |\n",
    "| $c$ | wave speed |\n",
    "| $\\mathbf{d}$ | observed dataset |\n",
    "| $\\delta\\mathbf{d}$ | residual dataset,  $\\delta\\mathbf{d}=\\mathbf{p}-\\mathbf{d}$|\n",
    "| $f$ | the functional (or objective/cost/misfit function)\n",
    "| $G$ | function that generates a wavefield from the model parameters |\n",
    "| $\\mathbf{m}$ | discretised model parameters |\n",
    "| $\\mathbf{m}_0$ | starting model parameters |\n",
    "| $\\delta\\mathbf{m}$ | perturbation to model parameters |\n",
    "| $n$ | number of parameters in a model |\n",
    "| $n_r$ | number of receivers |\n",
    "| $n_s$ | number of sources |\n",
    "| $n_t$ | number of time samples |\n",
    "| $\\mathbf{p}$ | a predicted dataset - typically this will be a subset of the wavefield $\\mathbf{u}$\n",
    "| $\\mathbf{R}$ | diagonal restriction matrix that selects a subset of a wavefield such that $\\mathbf{p}=\\mathbf{Ru}$ |\n",
    "| $s$ | source term |\n",
    "| $\\mathbf{s}$ | source term at all locations in a discretised model |\n",
    "| $t$ | time |\n",
    "| $u$ | the wavefield |\n",
    "| $\\mathbf{u}$ | the wavefield at all locations in a discretised model |\n",
    "| $\\delta\\mathbf{u}$ | wavefield generated through back-propagating the residuals |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The $L_2-norm$\n",
    "\n",
    "The square of the $L_2-norm$ for a *real* vector $\\mathbf{v}$ with $n$ elements is given by\n",
    "\n",
    "\\begin{equation}\n",
    "  ||\\mathbf{v}||^2 = \\mathbf{v}^T\\mathbf{v}=\\sum_{i=1}^{n}v_i^2.\n",
    "\\end{equation}\n",
    "\n",
    "It is the inner product of $\\mathbf{v}$ with itself. It represents the square of the length of the vector\n",
    "in Euclidean space. The $L_2-norm$ always has a non-negative real scalar value.\n",
    "If $\\mathbf{v}$ represents the difference between two vectors, say $\\mathbf{v}$ = $\\mathbf{v}_{computed}-\\mathbf{v}_{observation}$ , then the $L_2-norm$ represents the distance between the two vectors $\\mathbf{v}_{computed}$ and $\\mathbf{v}_{observation}$. It is the square of this quantity that is minimised in *least-squares* problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Gradient\n",
    "\n",
    "The *gradient* of the objective function $f$ with respect to the $n$ model parameters $\\mathbf{m}$ is given by\n",
    "\n",
    "\\begin{align}\n",
    "    \\nabla_{\\mathbf{m}}f &\\equiv \\frac{\\partial f}{\\partial\\mathbf{m}} &\\equiv \\begin{bmatrix}\n",
    "           \\frac{\\partial f}{\\partial m_1} \\\\\n",
    "           \\frac{\\partial f}{\\partial m_2} \\\\\n",
    "           \\vdots \\\\\n",
    "           \\frac{\\partial f}{\\partial m_n}\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}\n",
    "  \n",
    "The gradient is a vector that points in the direction of steepest ascent in the model space.\n",
    "That is, if the model parameters are changed (by an appropriate amount) in the opposite direction to the gradient, then the objective function will decrease fastest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Hessian\n",
    "\n",
    "The Hessian matrix describes the variation of the objective function with respect to changes\n",
    "in pairs of model parameters. It is a symmetric matrix of size $n\\times n$ if there are $n$ model\n",
    "parameters:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathbf{H} &\\equiv \\frac{\\partial^2 f}{\\partial \\mathbf{m}^2} &\\equiv\n",
    "      \\begin{bmatrix}\n",
    "           \\frac{\\partial^2 f}{\\partial m_1^2} & \\frac{\\partial^2 f}{\\partial m_1\\partial m_2} & \\cdots & \\frac{\\partial^2 f}{\\partial m_1\\partial m_n} \\\\\n",
    "           \\frac{\\partial^2 f}{\\partial m_2\\partial m_1} & \\frac{\\partial^2 f}{\\partial m_2^2} & \\cdots & \\frac{\\partial^2 f}{\\partial m_2\\partial m_n} \\\\  \n",
    "           \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "           \\frac{\\partial^2 f}{\\partial m_n\\partial m_1} & \\frac{\\partial^2 f}{\\partial m_n\\partial m_2} & \\cdots & \\frac{\\partial^2 f}{\\partial m_n^2}\n",
    "      \\end{bmatrix}\n",
    "  \\end{align}\n",
    "  \n",
    "The Hessian provides a measure of the local curvature of the $n$-dimensional error surface for\n",
    "the current model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
