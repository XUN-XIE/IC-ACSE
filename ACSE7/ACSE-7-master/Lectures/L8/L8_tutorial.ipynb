{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACSE-7 (Inversion and Optimisation)\n",
    "\n",
    "# Homework Lecture 8: Data Assimilation\n",
    "\n",
    "### Probabilities\n",
    "\n",
    "1. Show that given $n$ independent trials ${X_1, \\ldots X_n}$ taken from a random variable $X$, with mean $\\mu$ and variance $\\sigma^2$, we have the result\n",
    "$$ E\\left(\\left[\\sum_i X_i^2\\right]-\\frac{1}{n}\\left[\\sum_i X_i\\right]^2\\right) = (n-1)\\sigma^2.$$\n",
    "You may use the identities that $\\left(\\sum_{i=1}^n a_i\\right)^2=\\sum_{i=1}^n a_i^2+\\sum_{i=1}^n \\sum_{j\\neq i}  a_i a_j$, that $E(X+Y) = E(X)+E(Y)$ and that _for independent variables_ $E(XY) = E(X)E(Y)$. Remember the definitions $E(X_i)=\\mu$ and $E(X_i^2)-\\mu^2=\\sigma^2$ and that for a constant, $\\sum_{c=1}^nc= nc$.  \n",
    "\n",
    "2.  Prove the identity for covariances that \n",
    "$$ E \\left( [X-\\mu_X][Y-\\mu_Y]\\right) = E(XY)-\\mu_X\\mu_Y.$$\n",
    "You may use the facts that $\\mu_X:=E(X)$ and $\\mu_Y:=E(Y)$ are constants, that $E(aX) = aE(X)$ and that $E(a) = a$ for constant variables, as well as the identities given in question 1.\n",
    "3. The [polar method](https://apps.dtic.mil/dtic/tr/fulltext/u2/288931.pdf) to generate Gaussian random variables can be stated as follows:\n",
    "   1. Take a pair $(u,v)$ of uniform variables over $[-1,1]$.\n",
    "   2. Let $s=u^2+v^2$. If $s=0$ or $s>1$ goto A and try again.\n",
    "   3. Otherwise, calculate \n",
    "   $$x=u\\sqrt{\\frac{-2\\ln s}{s}}, \\quad y=v\\sqrt{\\frac{-2\\ln s}{s}}.$$ These will be normal random variables of zero mean and unit variance.\n",
    "   \n",
    "   Implement this method in Python. Plot a histogram of your results to confirm you have the correct distribution.\n",
    " Can you extend the method to work for arbitrary means and variances?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The BLUE\n",
    "\n",
    " 1. Try to extend the BLUE analysis to the case of three independent unbiased observations, then  optionally generalize it for $n$ observations. You can do this either using substitution (as in the lecture notes), or by using a Lagrange multiplier for the constraint $E(\\epsilon_\\mbox{guess})=0$.\n",
    " 2. The BLUE is the best (in the sense of minimum mean square error) linear unbiased estimator. Treating $T_t$ as a constant deterministic variable, can you find a better biased linear estimator, specified in terms of the $\\sigma_i^2$ and $T_t$? Why would this be no use in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal interpolation\n",
    "\n",
    "Run the following experiments with the example OI code from the lecture notes:\n",
    "  1. Try modifying the $\\sigma$s, including adding a \"real\" $\\sigma_R$ used to add the observation noise and a \"fake\" one used in the OI calculation.\n",
    "  1. Try adding some systematic biases into the observations. How large must these be before the mean square error of the analysis regularly exceeds that of the background?\n",
    "  2. Try adding the same observation twice, keeping $R$ diagonal. How should $R$ really change, and what difficulties does that introduce?\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as p\n",
    "from scipy.linalg import inv\n",
    "\n",
    "\n",
    "### define the standard deviation of the background and observations\n",
    "\n",
    "sigma_t = 1.0\n",
    "sigma_b = 1.0\n",
    "sigma_r = 1.0\n",
    "\n",
    "l_t = 0.2\n",
    "l_e = 0.1\n",
    "l_b = l_e\n",
    "\n",
    "s = np.linspace(0, np.pi)\n",
    "\n",
    "e_b = np.zeros(len(s))\n",
    "x_t = np.zeros(len(s))\n",
    "\n",
    "for _ in range(len(s)):\n",
    "    e_b += np.random.normal(0, sigma_b)*np.exp(-(s-s[_])**2/l_e**2)\n",
    "    x_t += np.random.normal(0, sigma_t)*np.exp(-(s-s[_])**2/l_t**2)\n",
    "\n",
    "x_b = x_t + e_b\n",
    "\n",
    "\n",
    "H = np.zeros((len(s)//5, len(s)))\n",
    "for _ in range(H.shape[0]):\n",
    "    H[_,5*_] = 1\n",
    "    \n",
    "y = np.dot(H, x_t) \n",
    "y += np.random.normal(0, 1, size=(y.shape))\n",
    "\n",
    "\n",
    "R = sigma_r**2*np.eye(y.shape[0])\n",
    "\n",
    "s2 = np.broadcast_to(s, (len(s), len(s)))\n",
    "B = sigma_b**2*np.exp(-(s2-s2.T)**2/l_b**2)\n",
    "\n",
    "W = B.dot((H.T)).dot(inv(R+H.dot(B.dot(H.T))))\n",
    "\n",
    "x_a = x_b + W.dot(y-H.dot(x_b))\n",
    "\n",
    "p.figure(figsize=(15, 6))\n",
    "p.plot(s, x_t, 'k', label='$x_t$, true state')\n",
    "p.plot(s, x_b, 'b', label='$x_b$, background guess')\n",
    "p.scatter(s[::5], y, label='obervation')\n",
    "p.plot(s, x_a, 'r', label='$x_a$, final analysis')\n",
    "p.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D - Var\n",
    "\n",
    "Run the following experiments with the example 3D-Var code from the lecture notes:\n",
    "\n",
    " 1. Try adding more observations, or some observations of the wind direction as well as speed. Which makes more difference to the analysis accuracy?\n",
    " 2. Rewrite the cost function in the example to use an iterative solver to calculate $\\mathbf{B}^{-1}(\\mathbf{x}-\\mathbf{x}_b)$ and $\\mathbf{R}^{-1}(\\mathbf{y}-\\mathbf{h}(\\mathbf{x}_b))$? Compare the time and memory requirements with the direct inversion method for a few problem sizes.\n",
    " 3. Experiment with other minimization methods; Can you provide a Jacobian function to speed things up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3D-Var implementation and solution\n",
    "\n",
    "# We will use some weather-like 2d data and generate the B from climatology.\n",
    "\n",
    "nx = 26\n",
    "ny = 11\n",
    "\n",
    "Lx = 1e6\n",
    "Ly = 4e5\n",
    "\n",
    "U_0 =  30.0\n",
    "radius = 5e4\n",
    "\n",
    "def wind_field(X, Y, circulations, centres):\n",
    "    \n",
    "    U = np.full((ny, nx), U_0)\n",
    "    V = np.zeros((ny, nx))\n",
    "    \n",
    "    for circ, (x, y) in zip(circulations, centres):\n",
    "        \n",
    "        r2= (X-x)**2 + (Y-y)**2\n",
    "        \n",
    "        u = circ/(2*np.pi)*np.where(r2>radius**2, 1./r2, 1.0/radius**2) \n",
    "        \n",
    "        \n",
    "        U -= (Y-y)*u\n",
    "        V += (X-x)*u\n",
    "        \n",
    "    return U, V\n",
    "\n",
    "X, Y = np.meshgrid(np.linspace(0,Lx,nx), np.linspace(0,Ly, ny))\n",
    "\n",
    "\n",
    "def random_vortices(N, kx=5, ky=5):\n",
    "    return (200*np.random.lognormal(0, 0.1, size=N)*radius,\n",
    "            np.random.uniform([-kx*radius, -kx*radius], [Lx+ky*radius, Ly+ky*radius], (N, 2)))\n",
    "\n",
    "U_t, V_t = wind_field(X, Y, *random_vortices(4, -1, -1))\n",
    "\n",
    "# observation locations\n",
    "n_full = 25\n",
    "n_speed = 25\n",
    "y_loc = np.random.randint(0, nx*ny, n_full+n_speed)\n",
    "# observation values\n",
    "y = np.empty(2*n_full+n_speed)\n",
    "y[:n_full] = U_t.ravel()[y_loc[:n_full]] + np.random.normal(0, 2.0, n_full)\n",
    "y[n_full:2*n_full] = V_t.ravel()[y_loc[:n_full]] + np.random.normal(0, 2.0, n_full)\n",
    "y[2*n_full:] = (np.sqrt(U_t.ravel()[y_loc[n_full:]]**2\n",
    "                      + V_t.ravel()[y_loc[n_full:]]**2)\n",
    "                      + np.random.normal(0, 2, n_speed))\n",
    "\n",
    "def h(x):\n",
    "    hx = np.empty(2*n_full+n_speed)\n",
    "    u = x[y_loc]\n",
    "    v = x[ny*nx+y_loc]\n",
    "    hx[:n_full] = u[:n_full] = u[:n_full]\n",
    "    hx[n_full:2*n_full] = v[:n_full]\n",
    "    hx[2*n_full:] = np.sqrt(u[n_full:]**2+v[n_full:]**2)\n",
    "    \n",
    "    return hx\n",
    "\n",
    "R = 2.0**2*np.eye(2*n_full+n_speed)\n",
    "\n",
    "U = np.empty((5000,ny,nx))\n",
    "V = np.empty((5000,ny,nx))\n",
    "\n",
    "for _ in range(U.shape[0]):\n",
    "    U[_, : :], V[_, :, :] = wind_field(X, Y, *random_vortices(4))\n",
    "\n",
    "mu_u = np.mean(U, 0)\n",
    "mu_v = np.mean(V, 0)\n",
    "\n",
    "d = np.empty((U.shape[0], 2*ny*nx))\n",
    "for _ in range(d.shape[0]):\n",
    "    d[_, :ny*nx] = (U[_, :]-mu_u).ravel() \n",
    "    d[_, ny*nx:] = (V[_, :]-mu_v).ravel()\n",
    "    \n",
    "B = np.empty((2*nx*ny, 2*nx*ny))\n",
    "for i in range(2*nx*ny):\n",
    "    for j in range(2*nx*ny):\n",
    "        B[i, j] = np.sum(d[:, i]*d[:, j])/(U.shape[0]-1)\n",
    "        \n",
    "x_b = np.empty(2*ny*nx)\n",
    "\n",
    "x_b[:ny*nx] = mu_u.ravel()\n",
    "x_b[ny*nx:] = mu_v.ravel()\n",
    "\n",
    "Binv = inv(B)\n",
    "Rinv = inv(R)\n",
    "\n",
    "def J(x):\n",
    "    dx_b = x-x_b\n",
    "    dx_o = y - h(x)\n",
    "    return np.dot(dx_b, Binv.dot(dx_b))+np.dot(dx_o,Rinv.dot(dx_o))\n",
    "\n",
    "def callback(x):\n",
    "    if False:\n",
    "        print(J(x))\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "res = minimize(J, x_b, method='CG', callback = callback, tol = 1e-3, options={'maxiter':100})\n",
    "x_a = res.x\n",
    "\n",
    "U_a = x_a[:ny*nx].reshape((ny,nx))\n",
    "V_a = x_a[ny*nx:].reshape((ny,nx))\n",
    "\n",
    "print('J for x_b:', J(x_b))\n",
    "print('J for x_a:', J(x_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 4. Consider the matrix problem\n",
    "\n",
    "$$\\left(\n",
    "\\begin{array}{cc}\n",
    "\\mathbf{R}&\\mathbf{H}\\\\\n",
    "\\mathbf{H}^T &-\\mathbf{B}^{-1}\n",
    "\\end{array}\n",
    "\\right)\\left(\n",
    "\\begin{array}{c}\n",
    "\\mathbf{a}\\\\\n",
    "\\mathbf{b}\n",
    "\\end{array}\n",
    "\\right)=\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "\\mathbf{c}\\\\\n",
    "\\mathbf{0}\n",
    "\\end{array}\n",
    "\\right).$$\n",
    " Write down the pair of vector equations this gives in non-matrix form. We want to generate an equation in the form $\\mathbf{a}=\\mathbf{K}\\mathbf{c}$, in two different ways:\n",
    "  - first, solving simultaneously, eliminate \\mathbf{b} to get an equation for $\\mathbf{a}$, then substitute into the seond equation to get the equation for $\\mathbf{b}$\n",
    "  - second, by eliminate $\\mathbf{a}$ between the two equations directly.\n",
    "By comparing the form of the results, can you see the connection to the lecture?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Kalman Filter\n",
    "\n",
    "  1. A hindcast is a \"forecast done backwards\". That is to say, the model is run backwards so that $\\mathbf{x}_{k-1}=\\mathbf{M}^{-1}\\mathbf{x}_k$. How do the Kalman Filter equations change if the system is run in reverse? In particular, how does the forecast covariance equation change? Modify the Kalman filter example to run backwards.\n",
    "  3. Modify the code from the lectures:\n",
    "    - Since the $\\mathbf{M}$ matrix is sparse here, create functions to calculate $\\mathbf{M}\\mathbf{x}$ and $\\mathbf{M}^T\\mathbf{x}$ directly (a.k.a \"matrix-free\"), rather than through matrix multiplication or the numpy.dot function. How big does nx need to be for this function to be faster? Can you make your function work on matrices?\n",
    "    - Modify the code to allow for arbitrary observations at moving locations. Can you find a good strategy to place them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kalman filter implementation for linearized vortices\n",
    "\n",
    "nx = 26\n",
    "ny = 11\n",
    "\n",
    "Lx = 10000\n",
    "Ly = 4000\n",
    "\n",
    "U_0 =  30.0\n",
    "radius = 500\n",
    "\n",
    "dt = Lx/(nx-1)/U_0\n",
    "vortices = random_vortices(200, 100)\n",
    "def advance_vortices(v):\n",
    "    v[1][:, 0] +=Lx/(nx-1)\n",
    "\n",
    "B_k = np.empty((2*ny*nx, 2*ny*nx))\n",
    "I = np.eye(2*ny*nx)\n",
    "M = np.zeros((2*ny*nx, 2*ny*nx))\n",
    "P = np.zeros((2*ny*nx, 2*ny*nx))\n",
    "Q = np.zeros((2*ny*nx, 2*ny*nx))\n",
    "Q[::nx,::nx] = B[::nx,::nx] # take forcing error from the statistics for B at x=0\n",
    "\n",
    "\n",
    "for j in range(ny):\n",
    "    for i in range(1, nx):\n",
    "        M[j*nx+i, j*nx+i-1] = 1\n",
    "        M[ny*nx+j*nx+i, nx*ny+j*nx+i-1] = 1\n",
    "        \n",
    "f_b = np.zeros(2*nx*ny)\n",
    "f_b[::nx] = x_b[::nx]  # boundary condition sets x_a = mean at x=0\n",
    "\n",
    "n_full = 5\n",
    "sigma_r = 1.0\n",
    "y_loc = np.random.randint(0, nx*ny, n_full)\n",
    "R_k = sigma_r**2*np.eye(2*n_full)\n",
    "H_k = np.zeros((2*n_full, 2*nx*ny))\n",
    "for i, j in enumerate(y_loc):\n",
    "    H_k[i, j] = 1.0\n",
    "    H_k[n_full+i,nx*ny+j] = 1.0\n",
    "B_k[:,:] = B\n",
    "\n",
    "\n",
    "nt = 40\n",
    "\n",
    "x_a = x_b # initialise with mean values\n",
    "P[:,:] = B\n",
    "\n",
    "for _ in range(nt):\n",
    "    advance_vortices(vortices)\n",
    "    U_t, V_t = wind_field(X, Y, *vortices)\n",
    "    x_t = np.concatenate((U_t.ravel(), V_t.ravel())) \n",
    "    \n",
    "    y = H_k.dot(x_t) + np.random.normal(0, sigma_r, size=2*n_full)\n",
    "    \n",
    "    # pull forward x\n",
    "    x_b_k = M.dot(x_a)+f_b\n",
    "    \n",
    "    \n",
    "    # pull forward P to B\n",
    "    B_k[:,:] = M.dot(P.dot(M.T)) + Q\n",
    "    # use innovations\n",
    "    W = B_k.dot((H_k.T)).dot(inv(R_k+H_k.dot(B_k.dot(H_k.T))))\n",
    "    x_a = x_b_k + W.dot(y-H_k.dot(x_b_k))\n",
    "    # calculate new P from B\n",
    "    P[:,:] = (I-W.dot(H_k)).dot(B_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4D-Var\n",
    "\n",
    "1. Consider the situation of running a 4D-Var assimilation for a discrete linear model, $\\mathbf{M}$, and linear observation operator $\\mathbf{H}$ taken over a time window of one timestep with observations only on at the end of the window, so that\n",
    "$$ \\mathbf{x}_1 = \\mathbf{M}\\mathbf{x}_0,$$\n",
    "$$\\mathcal{J} = \\frac{1}{2}(\\mathbf{x}_0-\\mathbf{x}_b)^T\\mathbf{B}^{-1}(\\mathbf{x}_0-\\mathbf{x}_b) + \\frac{1}{2}(\\mathbf{y}_1-\\mathbf{H}\\mathbf{x}_1)^T\\mathbf{R}^{-1}(\\mathbf{y}_1-\\mathbf{H}\\mathbf{x}_1).$$\n",
    "By direct substitution or otherwise, give the relevant optimal value of $\\mathbf{x}_1$, in the form $\\mathbf{x}_1 = \\mathbf{M}\\mathbf{x}_b +\\mathbf{W}(\\mathbf{y}-\\mathbf{H}\\mathbf{M}\\mathbf{x}_b).$. By comparing the optimal interpolation equation or linear 3D-Var solution, can you state the equivalent forecast error covariance matrix being used to assimilate $y_1$? How does this compare to the forward and hindcasting Kalman filter equations?\n",
    "2. Modify code from the lectures:\n",
    "  - vary the diffusion coefficient and advection speed in the forward and adjoint models. Which has more influence on the error? \n",
    "  - try setting inconsistent values in the adjoint model versus the forward model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4D var implementation for a diffusion problem with swarth observational data\n",
    "\n",
    "nx = 15\n",
    "nt = nx**2\n",
    "dt = 0.1\n",
    "dx = 1\n",
    "u = 0.2\n",
    "k = 2.0\n",
    "\n",
    "def forward_model(x0):\n",
    "    x = np.empty((nt, nx, nx))\n",
    "    x[0, :, :] = x0\n",
    "    \n",
    "    for t in range(1, nt):\n",
    "        x[t, ...] = x[t-1, ...]\n",
    "        x[t, 1:, :] += u*dt/dx*(x[t-1, :-1, :]-x[t-1, 1:, :])\n",
    "        x[t, :-1, :] += k*dt/dx**2*(x[t-1, 1:, :]**2-x[t-1, :-1,:]**2)\n",
    "        x[t, :, :-1] += k*dt/dx**2*(x[t-1, :, 1:]**2-x[t-1, :, :-1]**2)\n",
    "        x[t, :, 1:] += k*dt/dx**2*(x[t-1, :, :-1]**2-x[t-1, :, 1:]**2)\n",
    "        x[t, 1:, :] += k*dt/dx**2*(x[t-1, :-1, :]**2-x[t-1, 1:, :]**2)\n",
    "        \n",
    "    return x\n",
    "\n",
    "def adjoint_model(x, y, h):\n",
    "    l = -h[-1, ...].T.dot(y[-1, :]-h[-1, ...].dot(x[-1,...].ravel())).reshape((nx, nx))\n",
    "    for t in range(1, nt):\n",
    "        tmp = l.copy()\n",
    "        tmp[:-1, :] += u* dt/dx*(l[:-1, :]-l[1:, :])\n",
    "        z = x[-t-1, ...]*l\n",
    "        tmp[:-1, :] -= 2.0*k*dt/dx**2*(z[:-1, :]-z[:-1,:])\n",
    "        tmp[:, :-1] -= 2.0*k*dt/dx**2*(z[:, 1:]-z[:, :-1])\n",
    "        tmp[:, 1:] -= 2.0*k*dt/dx**2*(z[:, :-1]-z[:, 1:])\n",
    "        tmp[1:, :] -= 2.0*k*dt/dx**2*(z[:-1, :]-z[1:, :])\n",
    "        l = tmp - h[-t-1, ...].T.dot(y[-t-1, :]-h[-t-1, ...].dot(x[-t-1,...].ravel())).reshape((nx, nx))\n",
    "        \n",
    "    return l\n",
    "                \n",
    "    \n",
    "X, Y = np.meshgrid(np.linspace(0,nx-1,nx), np.linspace(0, nx-1, nx))\n",
    "x0 =np.exp(-((X-7)**2+(Y-4)**2)/4.0)\n",
    "x_t = forward_model(x0)\n",
    "\n",
    "\n",
    "X = X.ravel()\n",
    "Y = Y.ravel()\n",
    "\n",
    "Binv = np.empty((nx*nx, nx*nx))\n",
    "for i in range(nx*nx):\n",
    "    for j in range(nx*nx):\n",
    "        d2 = (X[i]-X[j])**2\n",
    "        dx += (Y[i]-Y[j])**2\n",
    "        Binv[i, j] = 0.05*np.exp(-0.1*d2)\n",
    "        \n",
    "\n",
    "h = np.zeros((nt, 1, nx**2))\n",
    "y = np.zeros((nt, 1))\n",
    "x_o = np.zeros((nx, nx))\n",
    "\n",
    "for _ in range(nt):\n",
    "    h [_, 0, (_%nx)*nx+_//nx] = 1\n",
    "    y[_, :] = h[_, :, :].dot(x_t[_, ...].ravel())\n",
    "    x_o += (h[_, :, :].T.dot(h[_, :, :].dot(x_t[_, ...].ravel()))).reshape((nx, nx))\n",
    "\n",
    "x_b = np.zeros((nx*nx))\n",
    "\n",
    "\n",
    "def j(x0, y, h):\n",
    "    x = forward_model(x0.reshape(nx, nx))\n",
    "    j_b0 = 0.5*(x0-x_b).dot(Binv.dot((x0-x_b)))\n",
    "    j_b = j_b0\n",
    "    for _ in range(nt):\n",
    "        j_b += 0.5*np.sum((y[_, :]-h[_, ...].dot(x[_,:, :].ravel()))**2)\n",
    "    return j_b\n",
    "\n",
    "def jac(x0, y, h):\n",
    "    x = forward_model(x0.reshape(nx, nx))\n",
    "    jac= Binv.dot(x0-x_b) + adjoint_model(x, y, h).ravel()\n",
    "    return jac\n",
    "\n",
    "from scipy.optimize.linesearch import line_search_armijo as line_search\n",
    "\n",
    "x_a = x_b.copy()\n",
    "j0 = j(x_a, y, h)\n",
    "for _ in range(100):\n",
    "    pk = -jac(x_a, y, h)\n",
    "    res = line_search(j, x_a, pk, -pk, j0, args=(y, h), alpha0=0.5)\n",
    "    x_a += res[0]*pk\n",
    "    j0 = res[2]\n",
    "    if res[0]<0.01:\n",
    "        break\n",
    "\n",
    "j0 = jac(x_b, y, h)\n",
    "\n",
    "print('Cost function for $x_b$', j(x_b, y, h))\n",
    "print('Cost function for $x_a$', j(x_a, y, h))\n",
    "\n",
    "\n",
    "x_f = forward_model(x_a.reshape((nx, nx)))\n",
    "\n",
    "p.figure()\n",
    "p.pcolormesh(x_b.reshape((nx, nx)), vmin=0, vmax=1)\n",
    "p.colorbar()\n",
    "\n",
    "p.figure()\n",
    "p.pcolormesh(x_f[0, ...])\n",
    "p.colorbar()\n",
    "\n",
    "p.figure()\n",
    "p.pcolormesh(x_t[0, ...])\n",
    "p.colorbar();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
